<!DOCTYPE HTML><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta name="baidu-site-verification" content="kZmc8XTvrB"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?458cfc1440d057b6b8799400c6b2e2bf";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><meta charset="utf-8"><title>机器学习（十一） 机器学习工作流 | 机器学习 and 数据科学</title><meta name="author" content="王小鹏  京ICP备19037345号-1"><meta name="keywords" content="机器学习,机器学习工作流 PDF电子书下载,电子书，PDF下载"><meta name="description" content="PDF电子书下载,电子书，PDF下载"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta property="og:title" content="机器学习（十一） 机器学习工作流"><meta property="og:site_name" content="机器学习 and 数据科学"><meta property="og:image" content><link href="/favicon.png" rel="icon"><link rel="alternate" href="/atom.xml" title="机器学习 and 数据科学" type="application/atom+xml"><link rel="stylesheet" href="/css/style.css" media="screen" type="text/css"><!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]--></head><body><header id="header" class="inner"><div class="alignleft"><h1><a href="/">机器学习 and 数据科学</a></h1><h2><a href="/">明天幸福今天修</a></h2></div><nav id="main-nav" class="alignright"><ul><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/about">关于</a></li></ul><div class="clearfix"></div></nav><div class="clearfix"></div></header><div id="content" class="inner"><div id="main-col" class="alignleft"><div id="wrapper"><article id="post-ml-ml11" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting"><div class="post-content"><header><div class="icon"></div><time class="dt-published" datetime="2019-11-15T14:35:05.000Z"><a href="/machinelearning/ml-ml11/">2019-11-15</a><span id="busuanzi_container_page_pv"> &nbsp;&nbsp;&nbsp;&nbsp;阅读 <span id="busuanzi_value_page_pv"></span></span></time><h1 class="p-name title" itemprop="headline name">机器学习（十一） 机器学习工作流</h1></header><div class="e-content entry" itemprop="articleBody"><p>标签： machine learning</p><p><img src="http://wangpengcufe.com/ml11-0.png" alt="目录"></p><a id="more"></a><h1 id="一、概念"><a href="#一、概念" class="headerlink" title="一、概念"></a><strong>一、概念</strong></h1><p>一个典型的机器学习过程从数据收集开始，要经历多个步骤，才能得到需要的输出。这非常类似于流水线式工作，即通常会包含源数据ETL（抽取、转化、加载），数据预处理，指标提取，模型训练与交叉验证，新数据预测等步骤。</p><p>MLlib标准化了用于机器学习算法的API，从而使将多种算法组合到单个管道或工作流程中变得更加容易。 本节介绍了Pipelines API引入的关键概念，其中PipeLine（管道）概念主要受scikit-learn项目的启发。</p><p>在介绍工作流之前，我们先来了解几个重要概念：</p><ul><li><p><strong>DataFrame</strong>：使用Spark SQL中的DataFrame作为ML数据集，该数据集可以保存各种数据类型。 例如，DataFrame可以具有不同的列，用于存储文本，特征向量，真实标签和预测。</p></li><li><p><strong>Transformer</strong>：翻译成转换器，是一种算法，可以将一个DataFrame转换为另一个DataFrame。 例如，ML模型是一个Transformer，它将具有特征的DataFrame转换为具有预测的DataFrame。</p></li><li><p><strong>Estimator</strong>：翻译成评估器，它是学习算法或在训练数据上的训练方法的概念抽象。在 Pipeline 里通常是被用来操作 DataFrame 数据并生产一个 Transformer。从技术上讲，Estimator实现了一个方法fit（），它接受一个DataFrame并产生一个转换器。例如，诸如LogisticRegression之类的学习算法是Estimator，调用fit（）可以训练LogisticRegressionModel，后者是Model，因此是Transformer。</p></li><li><p><strong>Parameter</strong>：Parameter 被用来设置 Transformer 或者 Estimator 的参数。现在，所有转换器和估计器可共享用于指定参数的公共API。ParamMap是一组（参数，值）对。</p></li><li><p><strong>PipeLine</strong>：翻译为工作流或者管道。管道将多个“变形器”和“估计器”链接在一起，以指定ML工作流程，并获得结果输出。 例如，简单的文本文档处理工作流程可能包括几个阶段：<br>1、将每个文档的文本拆分为单词。<br>2、将每个文档的单词转换成数字特征向量。<br>3、使用特征向量和标签学习预测模型。<br>MLlib将这样的工作流表示为“管道”，它由要按特定顺序运行的一系列PipelineStages（变压器和估计器）组成。</p></li></ul><h1 id="二、工作原理"><a href="#二、工作原理" class="headerlink" title="二、工作原理"></a>二、工作原理</h1><p>要构建一个 Pipeline工作流，首先需要定义 Pipeline 中的各个工作流阶段PipelineStage，（包括转换器和评估器），比如指标提取和转换模型训练等。有了这些处理特定问题的转换器和 评估器，就可以按照具体的处理逻辑有序的组织PipelineStages 并创建一个Pipeline。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pipeline pipeline = new Pipeline().setStages(new  PipelineStage[]&#123;tokenizer,hashingTF,lr&#125;);</span><br></pre></td></tr></table></figure><p>然后就可以把训练数据集作为输入参数，调用 Pipeline 实例的 fit 方法来开始以流的方式来处理源训练数据。这个调用会返回一个 PipelineModel 类实例，进而被用来预测测试数据的标签。更具体的说，工作流的各个阶段按顺序运行，输入的DataFrame在它通过每个阶段时被转换。 对于Transformer阶段，在DataFrame上调用transform（）方法。 对于估计器阶段，调用fit（）方法来生成一个转换器（它成为PipelineModel的一部分或拟合的Pipeline），并且在DataFrame上调用该转换器的transform（）方法。</p><p><img src="http://wangpengcufe.com/ml11.png" alt="Pipeline原理1"></p><p>上面，顶行表示具有三个阶段的流水线。 前两个（Tokenizer和HashingTF）是Transformers（蓝色），第三个（LogisticRegression）是Estimator（红色）。 底行表示流经管线的数据，其中圆柱表示DataFrames。 在原始DataFrame上调用Pipeline.fit（）方法，它具有原始文本文档和标签。 Tokenizer.transform（）方法将原始文本文档拆分为单词，向DataFrame添加一个带有单词的新列。 HashingTF.transform（）方法将字列转换为特征向量，向这些向量添加一个新列到DataFrame。 现在，由于LogisticRegression是一个Estimator，Pipeline首先调用LogisticRegression.fit（）产生一个LogisticRegressionModel。 如果流水线有更多的阶段，则在将DataFrame传递到下一个阶段之前，将在DataFrame上调用LogisticRegressionModel的transform（）方法。</p><p>值得注意的是，工作流本身也可以看做是一个估计器。在工作流的fit（）方法运行之后，它产生一个PipelineModel，它是一个Transformer。 这个管道模型将在测试数据的时候使用。 下图说明了这种用法。</p><p><img src="http://wangpengcufe.com/ml11-2.png" alt="Pipeline原理2"></p><p>在上图中，PipelineModel具有与原始流水线相同的级数，但是原始流水线中的所有估计器都变为变换器。 当在测试数据集上调用PipelineModel的transform（）方法时，数据按顺序通过拟合的工作流。 每个阶段的transform（）方法更新数据集并将其传递到下一个阶段。工作流和工作流模型有助于确保培训和测试数据通过相同的特征处理步骤。</p><h1 id="三、代码实现"><a href="#三、代码实现" class="headerlink" title="三、代码实现"></a>三、代码实现</h1><p>以逻辑斯蒂回归为例，构建一个典型的机器学习过程，来具体介绍一下工作流是如何应用的。我们的目的是查找出所有包含”spark”的句子，即将包含”spark”的句子的标签设为1，没有”spark”的句子的标签设为0。</p><h3 id="3-1、构建训练数据集"><a href="#3-1、构建训练数据集" class="headerlink" title="3.1、构建训练数据集"></a><strong>3.1、构建训练数据集</strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">import java.util.Arrays;</span><br><span class="line">import java.util.List;</span><br><span class="line">import org.apache.spark.ml.Pipeline;</span><br><span class="line">import org.apache.spark.ml.PipelineModel;</span><br><span class="line">import org.apache.spark.ml.PipelineStage;</span><br><span class="line">import org.apache.spark.ml.classification.LogisticRegression;</span><br><span class="line">import org.apache.spark.ml.feature.HashingTF;</span><br><span class="line">import org.apache.spark.ml.feature.Tokenizer;</span><br><span class="line">import org.apache.spark.sql.Dataset;</span><br><span class="line">import org.apache.spark.sql.Row;</span><br><span class="line">import org.apache.spark.sql.RowFactory;</span><br><span class="line">import org.apache.spark.sql.SparkSession;</span><br><span class="line">import org.apache.spark.sql.types.DataTypes;</span><br><span class="line">import org.apache.spark.sql.types.Metadata;</span><br><span class="line">import org.apache.spark.sql.types.StructField;</span><br><span class="line">import org.apache.spark.sql.types.StructType;</span><br><span class="line">SparkSession spark = SparkSession.builder().appName(&quot;MLPipelines&quot;).master(&quot;local&quot;).getOrCreate();</span><br><span class="line">//构建训练数据集</span><br><span class="line">List&lt;Row&gt; data = Arrays.asList(RowFactory.create(0L, &quot;a b c d e spark&quot;, 1.0),</span><br><span class="line">                               RowFactory.create(1L, &quot;b d&quot;, 0.0),</span><br><span class="line">                               RowFactory.create(2L, &quot;spark f g h&quot;, 1.0),</span><br><span class="line">                               RowFactory.create(3L, &quot;hadoop mapreduce&quot;, 0.0));</span><br><span class="line">System.out.println(data);</span><br><span class="line">/**</span><br><span class="line">*控制台输出结果：</span><br><span class="line">-------------------------------------------------------------------------------------</span><br><span class="line">[[0,a b c d e spark,1.0], [1,b d,0.0], [2,spark f g h,1.0], [3,hadoop mapreduce,0.0]]</span><br><span class="line">-------------------------------------------------------------------------------------</span><br><span class="line">**/</span><br><span class="line">StructType schema = new StructType(new StructField[] &#123;</span><br><span class="line">    new StructField(&quot;id&quot;,DataTypes.LongType,false,Metadata.empty()),</span><br><span class="line">    new StructField(&quot;text&quot;, DataTypes.StringType, false, Metadata.empty()),</span><br><span class="line">    new StructField(&quot;label&quot;, DataTypes.DoubleType, false, Metadata.empty()),</span><br><span class="line">&#125;);</span><br><span class="line">Dataset&lt;Row&gt; training = spark.createDataFrame(data,schema);</span><br><span class="line">training.show(false);</span><br><span class="line">/**</span><br><span class="line">*控制台输出结果：</span><br><span class="line">    +---+----------------+-----+</span><br><span class="line">    |id |text            |label|</span><br><span class="line">    +---+----------------+-----+</span><br><span class="line">    |0  |a b c d e spark |1.0  |</span><br><span class="line">    |1  |b d             |0.0  |</span><br><span class="line">    |2  |spark f g h     |1.0  |</span><br><span class="line">    |3  |hadoop mapreduce|0.0  |</span><br><span class="line">    +---+----------------+-----+</span><br><span class="line">**/</span><br></pre></td></tr></table></figure><h3 id="3-2、定义-Pipeline-中的各个工作流阶段PipelineStage"><a href="#3-2、定义-Pipeline-中的各个工作流阶段PipelineStage" class="headerlink" title="3.2、定义 Pipeline 中的各个工作流阶段PipelineStage"></a><strong>3.2、定义 Pipeline 中的各个工作流阶段PipelineStage</strong></h3><p>在这一步中我们要定义 Pipeline 中的各个工作流阶段PipelineStage，包括转换器和评估器，具体的，包含tokenizer, hashingTF和lr三个步骤。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Tokenizer tokenizer = new Tokenizer().setInputCol(&quot;text&quot;)</span><br><span class="line">                                     .setOutputCol(&quot;words&quot;);</span><br><span class="line"></span><br><span class="line">HashingTF hashingTF = new HashingTF().setNumFeatures(1000)</span><br><span class="line">                                     .setInputCol(tokenizer.getOutputCol())</span><br><span class="line">                                     .setOutputCol(&quot;features&quot;);</span><br><span class="line"></span><br><span class="line">LogisticRegression lr = new LogisticRegression().setMaxIter(10).setRegParam(0.01);</span><br></pre></td></tr></table></figure><h3 id="3-3、创建一个Pipeline"><a href="#3-3、创建一个Pipeline" class="headerlink" title="3.3、创建一个Pipeline"></a><strong>3.3、创建一个Pipeline</strong></h3><p>有了这些处理特定问题的转换器和评估器，接下来就可以按照具体的处理逻辑有序的组织PipelineStages 并创建一个Pipeline。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Pipeline pipeline = new Pipeline().setStages(new PipelineStage[]&#123;tokenizer,hashingTF,lr&#125;);</span><br></pre></td></tr></table></figure><h3 id="3-4、创建模型"><a href="#3-4、创建模型" class="headerlink" title="3.4、创建模型"></a><strong>3.4、创建模型</strong></h3><p>现在构建的Pipeline本质上是一个Estimator，在它的fit（）方法运行之后，它将产生一个PipelineModel，它是一个Transformer。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PipelineModel model = pipeline.fit(training);</span><br></pre></td></tr></table></figure><p>我们可以看到，model的类型是一个PipelineModel，这个管道模型将在测试数据的时候使用。所以接下来，我们先构建测试数据。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Row&gt; testRaw = Arrays.asList(RowFactory.create(4L, &quot;spark i j k&quot;),</span><br><span class="line">        RowFactory.create(5L, &quot;l m n&quot;),</span><br><span class="line">        RowFactory.create(6L, &quot;spark a&quot;),</span><br><span class="line">        RowFactory.create(7L, &quot;apache hadoop&quot;)</span><br><span class="line">        );</span><br><span class="line">Dataset&lt;Row&gt; test = spark.createDataFrame(testRaw,schema);</span><br><span class="line">test.select(&quot;id&quot;, &quot;text&quot;).show(false);</span><br><span class="line">/**</span><br><span class="line">*控制台输出结果：</span><br><span class="line">    +---+-------------+</span><br><span class="line">    |id |text         |</span><br><span class="line">    +---+-------------+</span><br><span class="line">    |4  |spark i j k  |</span><br><span class="line">    |5  |l m n        |</span><br><span class="line">    |6  |spark a      |</span><br><span class="line">    |7  |apache hadoop|</span><br><span class="line">    +---+-------------+</span><br><span class="line">**/</span><br></pre></td></tr></table></figure><h3 id="3-5、预测结果"><a href="#3-5、预测结果" class="headerlink" title="3.5、预测结果"></a><strong>3.5、预测结果</strong></h3><p>然后，我们调用我们训练好的PipelineModel的transform（）方法，让测试数据按顺序通过拟合的工作流，生成我们所需要的预测结果。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">model.transform(test).select(&quot;id&quot;,  &quot;text&quot;, &quot;probability&quot;,  &quot;prediction&quot;).show(false);</span><br><span class="line">/**</span><br><span class="line">    *控制台输出结果：</span><br><span class="line">   +---+--------------+----------------------------------------+----------+</span><br><span class="line">   |id |text          |probability                             |prediction|</span><br><span class="line">   +---+--------------+----------------------------------------+----------+</span><br><span class="line">   |4  |spark i j k   |[0.540643354485232,0.45935664551476796] |0.0       |</span><br><span class="line">   |5  |l m n         |[0.9334382627383527,0.06656173726164716]|0.0       |</span><br><span class="line">   |6  |spark a       |[0.1504143004807332,0.8495856995192668] |1.0       |</span><br><span class="line">   |7  |apache  hadoop|[0.9768636139518375,0.02313638604816238]|0.0       |</span><br><span class="line">   +---+--------------+----------------------------------------+----------+</span><br><span class="line">**/</span><br></pre></td></tr></table></figure><p>通过上述结果，我们可以看到，第4句和第6句中都包含”spark”，其中第六句的预测是1，与我们希望的相符；而第4句虽然预测的依然是0，但是通过概率我们可以看到，第4句有46%的概率预测是1，而第5句、第7句分别只有7%和2%的概率预测为1，这是由于训练数据集较少，如果有更多的测试数据进行学习，预测的准确率将会有显著提升。</p><p><strong>参考资料：</strong><a href="http://spark.apache.org/docs/latest/ml-pipeline.html" title="http://spark.apache.org/docs/latest/ml-pipeline.html" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/ml-pipeline.html</a></p></div><footer><div class="categories"><a href="/categories/machinelearning/">机器学习</a></div><div class="tags"><a href="/tags/content/">content</a>, <a href="/tags/machine-learning/">machine learning</a></div><div class="addthis addthis_toolbox addthis_default_style"><a class="addthis_button_facebook_like" fb:like:layout="button_count"></a> <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a> <a class="addthis_counter addthis_pill_style"></a></div><script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script><div class="clearfix"></div></footer></div></article><section id="comment"><h1 class="title">留言</h1><div id="fb-root"></div><script>!function(e,t,n){var a,c=e.getElementsByTagName(t)[0];e.getElementById(n)||((a=e.createElement(t)).id=n,a.src="//connect.facebook.net/en_US/all.js#xfbml=1&appId=123456789012345",c.parentNode.insertBefore(a,c))}(document,"script","facebook-jssdk")</script><div class="fb-comments" data-href="http://www.wangpengcufe.com/machinelearning/ml-ml11/index.html" data-num-posts="5" data-width="840" data-colorscheme="light"></div></section></div></div><aside id="sidebar" class="alignright"><script language="javascript">function search(e){return e.method="get",e.action="http://www.baidu.com/baidu",document.search_form.word.value=document.search_form.word.value,!0}</script><div class="search"><form name="search_form" target="_blank" onsubmit="search(this)"><input type="search" name="word" results="0" placeholder="百度站内搜索" onblur='this.value=""'></form></div><div class="widget tag"><h3 class="title">分类</h3><ul class="entry"><li><a href="/categories/read/">read</a><small>63</small></li><li><a href="/categories/tools/">工具</a><small>2</small></li><li><a href="/categories/machinelearning/">机器学习</a><small>21</small></li><li><a href="/categories/navigate/">菜单导航</a><small>1</small></li><li><a href="/categories/datadownload/">资料下载</a><small>1</small></li></ul></div><div class="widget tag"><h3 class="title">标签</h3><ul class="entry"><li><a href="/tags/content/">content</a><small>85</small></li><li><a href="/tags/library/">library</a><small>1</small></li><li><a href="/tags/machine-learning/">machine learning</a><small>21</small></li><li><a href="/tags/navigate/">navigate</a><small>1</small></li><li><a href="/tags/tools/">tools</a><small>2</small></li></ul></div><div class="widget tag"><h3 class="title">友情链接</h3><ul class="entry"><li><a href="http://blog.didispace.com" title="程序员DD">程序员DD</a></li><li><a href="https://mangoroom.cn" title="芒果的个人博客">芒果的个人博客</a></li><li><a href="http://www.baimin.com" target="_blank">百鸣网站百科</a></li><li><a href="http://blog.sina.com.cn/u/2435344920" target="_blank">默默读书</a></li><li><a href="https://www.jianshu.com/u/510007ddad06" target="_blank">王小鹏的随笔（简书）</a></li><li><a href="https://me.csdn.net/weixin_42438712" target="_blank">机器学习（csdn博客）</a></li><li><a href="https://zhuanlan.zhihu.com/c_1182309165824901120" target="_blank">机器学习（知乎）</a></li><li><a href="http://meixiaohan.com/" target="_blank">小寒大人的blog</a></li><li><a href="https://baippt.com/" target="_blank">ppt模板免费下载</a></li><li><a href="http://www.youneedcn.com/" target="_blank">你要的资源</a></li></ul></div></aside><div class="clearfix"></div></div><footer id="footer" class="inner"><div class="alignleft">&copy; 2020 王小鹏 京ICP备19037345号-1</div><div class="clearfix"></div><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></footer><script src="//ajax.useso.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script><script src="/js/jquery.imagesloaded.min.js"></script><script src="/js/gallery.js"></script><link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css"><script src="/fancybox/jquery.fancybox.pack.js"></script><script type="text/javascript">jQuery(".fancybox").fancybox()</script></body></html>