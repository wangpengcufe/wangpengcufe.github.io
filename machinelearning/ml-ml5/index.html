<!DOCTYPE HTML><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta name="baidu-site-verification" content="kZmc8XTvrB"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?458cfc1440d057b6b8799400c6b2e2bf";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><meta charset="utf-8"><title>机器学习 （五）逻辑斯蒂回归 | 机器学习 and 数据科学</title><meta name="author" content="王小鹏  京ICP备19037345号-1"><meta name="description" content="PDF电子书下载,电子书，PDF下载，电子书下载，PDF电子书免费下载"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta property="og:title" content="机器学习 （五）逻辑斯蒂回归"><meta property="og:site_name" content="机器学习 and 数据科学"><meta property="og:image" content><link href="/favicon.png" rel="icon"><link rel="alternate" href="/atom.xml" title="机器学习 and 数据科学" type="application/atom+xml"><link rel="stylesheet" href="/css/style.css" media="screen" type="text/css"><!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]--></head><body><header id="header" class="inner"><div class="alignleft"><h1><a href="/">机器学习 and 数据科学</a></h1><h2><a href="/">明天幸福今天修</a></h2></div><nav id="main-nav" class="alignright"><ul><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/about">关于</a></li></ul><div class="clearfix"></div></nav><div class="clearfix"></div></header><div id="content" class="inner"><div id="main-col" class="alignleft"><div id="wrapper"><article id="post-ml-ml5" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting"><div class="post-content"><header><div class="icon"></div><time class="dt-published" datetime="2019-09-01T09:20:39.000Z"><a href="/machinelearning/ml-ml5/">2019-09-01</a><span id="busuanzi_container_page_pv"> &nbsp;&nbsp;&nbsp;&nbsp;阅读 <span id="busuanzi_value_page_pv"></span></span></time><h1 class="p-name title" itemprop="headline name">机器学习 （五）逻辑斯蒂回归</h1></header><div class="e-content entry" itemprop="articleBody"><p>标签： machine learning</p><p><img src="/machinelearning/ml-ml5/1.png" alt="图1"></p><a id="more"></a><h1 id="一、概念"><a href="#一、概念" class="headerlink" title="一、概念"></a><strong>一、概念</strong></h1><p>逻辑斯蒂回归（logistic regression）是统计学习中的经典分类方法，属于对数线性模型。logistic回归的因变量可以是二分类的，也可以是多分类的。logistic回归的因变量可以是二分非线性差分方程类的，也可以是多分类的，但是二分类的更为常用，也更加容易解释。所以实际中最为常用的就是二分类的logistic回归。</p><h1 id="二、logistic分布"><a href="#二、logistic分布" class="headerlink" title="二、logistic分布"></a><strong>二、logistic分布</strong></h1><p>设X是连续随机变量，X服从逻辑斯蒂分布是指X具有下列分布函数和密度函数：</p><p><img src="/machinelearning/ml-ml5/2.png" alt="图2"></p><p>式中，μ为位置参数，γ&gt;0为形状参数。</p><p>密度函数是脉冲函数</p><p>分布函数是一条Sigmoid曲线(sigmoid curve)即为阶跃函数</p><p><img src="/machinelearning/ml-ml5/3.png" alt="图3"></p><h1 id="三、二项逻辑斯谛回归模型"><a href="#三、二项逻辑斯谛回归模型" class="headerlink" title="三、二项逻辑斯谛回归模型"></a><strong>三、二项逻辑斯谛回归模型</strong></h1><p>二项逻辑斯谛回归模型是如下的条件概率分布</p><p><img src="/machinelearning/ml-ml5/4.png" alt="图4"></p><p>x∊Rn是输入，Y∊{0,1}是输出，w∊Rn和b∊R是参数，</p><p>w称为权值向量，b称为偏置，w·x为w和x的内积。</p><p>可以求得P(Y＝1|x)和P(Y＝0|x)。</p><p>逻辑斯谛回归比较两个条件概率值的大小，将实例x分到概率值较大的那一类。</p><h1 id="四、LR模型参数估计"><a href="#四、LR模型参数估计" class="headerlink" title="四、LR模型参数估计"></a><strong>四、LR模型参数估计</strong></h1><p>可以应用极大似然估计法估计模型参数</p><p><img src="/machinelearning/ml-ml5/5.png" alt="图5"></p><p>对L(w)求极大值，得到w的估计值。</p><p>问题就变成了以对数似然函数为目标函数的最优化问题。</p><p>LR学习中通常采用的方法是梯度下降法及拟牛顿法。</p><h1 id="五、代码实现"><a href="#五、代码实现" class="headerlink" title="五、代码实现"></a><strong>五、代码实现</strong></h1><p>我们以iris数据集（<a href="https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data）" target="_blank" rel="noopener">https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data）</a> 为例进行分析。iris以鸢尾花的特征作为数据来源，数据集包含150个数据集，分为3类，每类50个数据，每个数据包含4个属性，是在数据挖掘、数据分类中非常常用的测试集、训练集。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.spark.SparkConf;</span><br><span class="line">import org.apache.spark.SparkContext;</span><br><span class="line">import org.apache.spark.api.java.JavaPairRDD;</span><br><span class="line">import org.apache.spark.api.java.JavaRDD;</span><br><span class="line">import org.apache.spark.mllib.classification.LogisticRegressionModel;</span><br><span class="line">import org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS;</span><br><span class="line">import org.apache.spark.mllib.evaluation.MulticlassMetrics;</span><br><span class="line">import org.apache.spark.mllib.regression.LabeledPoint;</span><br><span class="line">import org.apache.spark.mllib.util.MLUtils;</span><br></pre></td></tr></table></figure><h2 id="5-1、读取数据"><a href="#5-1、读取数据" class="headerlink" title="5.1、读取数据"></a><strong>5.1、读取数据</strong></h2><p>首先，读取文本文件；然后，通过map将每行的数据用“,”隔开，在我们的数据集中，每行被分成了5部分，前4部分是鸢尾花的4个特征，最后一部分是鸢尾花的分类。把这里我们用LabeledPoint来存储标签列和特征列。<br>LabeledPoint在监督学习中常用来存储标签和特征，其中要求标签的类型是double，特征的类型是Vector。这里，先把莺尾花的分类进行变换，”Iris-setosa”对应分类0，”Iris-versicolor”对应分类1，其余对应分类2；然后获取莺尾花的4个特征，存储在Vector中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">SparkConf conf = new  SparkConf().setAppName(&quot;LogisticRegression&quot;).setMaster(&quot;local&quot;);</span><br><span class="line">JavaSparkContext sc = new  JavaSparkContext(conf);</span><br><span class="line">JavaRDD&lt;String&gt; source =  sc.textFile(&quot;data/mllib/iris.data&quot;);</span><br><span class="line"></span><br><span class="line">JavaRDD&lt;LabeledPoint&gt; data = source.map(line-&gt;&#123;</span><br><span class="line">            String[] splits = line.split(&quot;,&quot;);</span><br><span class="line">            Double label = 0.0;</span><br><span class="line">            if(splits[4].equals(&quot;Iris-setosa&quot;))  &#123;</span><br><span class="line">                label = 0.0;</span><br><span class="line">            &#125;else  if(splits[4].equals(&quot;Iris-versicolor&quot;)) &#123;</span><br><span class="line">                label = 1.0;</span><br><span class="line">            &#125;else &#123;</span><br><span class="line">                label = 2.0;</span><br><span class="line">            &#125;</span><br><span class="line">            return new  LabeledPoint(label,Vectors.dense(Double.parseDouble(splits[0]),</span><br><span class="line">                    Double.parseDouble(splits[1]),</span><br><span class="line">                    Double.parseDouble(splits[2]),</span><br><span class="line">                    Double.parseDouble(splits[3])));</span><br><span class="line"> &#125;);</span><br></pre></td></tr></table></figure><p>打印数据：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">// 控制台输出结果：</span><br><span class="line">(0.0,[5.1,3.5,1.4,0.2])</span><br><span class="line">(0.0,[4.9,3.0,1.4,0.2])</span><br><span class="line">(0.0,[4.7,3.2,1.3,0.2])</span><br><span class="line">(0.0,[4.6,3.1,1.5,0.2])</span><br><span class="line">(0.0,[5.0,3.6,1.4,0.2])</span><br><span class="line">(0.0,[5.4,3.9,1.7,0.4])</span><br><span class="line">(0.0,[4.6,3.4,1.4,0.3])</span><br><span class="line">(0.0,[5.0,3.4,1.5,0.2])</span><br><span class="line">(0.0,[4.4,2.9,1.4,0.2])</span><br><span class="line">(0.0,[4.9,3.1,1.5,0.1])</span><br><span class="line">(0.0,[5.4,3.7,1.5,0.2])</span><br><span class="line">... ...</span><br></pre></td></tr></table></figure><h2 id="5-2、构建模型："><a href="#5-2、构建模型：" class="headerlink" title="5.2、构建模型："></a><strong>5.2、构建模型：</strong></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// 首先进行数据集的划分，这里划分60%的训练集和40%的测试集：</span><br><span class="line">JavaRDD&lt;LabeledPoint&gt;[] splits =  data.randomSplit(new double[] &#123;0.6,0.4&#125;,11L);</span><br><span class="line">JavaRDD&lt;LabeledPoint&gt; traning =  splits[0].cache();</span><br><span class="line">JavaRDD&lt;LabeledPoint&gt; test = splits[1];</span><br></pre></td></tr></table></figure><p>构建逻辑斯蒂模型，用set的方法设置参数，比如说分类的数目，这里可以实现多分类逻辑斯蒂模型:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LogisticRegressionModel model = new LogisticRegressionWithLBFGS().setNumClasses(3).run(traning.rdd());</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">org.apache.spark.mllib.classification.LogisticRegressionModel: intercept = 0.0,  numFeatures = 8, numClasses = 3, threshold = 0.5</span><br></pre></td></tr></table></figure><p>接下来，调用多分类逻辑斯蒂模型用的predict方法对测试数据进行预测，并把结果保存在MulticlassMetrics中。这里的模型全名为LogisticRegressionWithLBFGS，加上了LBFGS，表示Limited-memory BFGS。其中，BFGS是求解非线性优化问题（L(w)求极大值）的方法，是一种秩-2更新，以其发明者Broyden, Fletcher, Goldfarb和Shanno的姓氏首字母命名。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">JavaPairRDD&lt;Object,Object&gt; predictionAndLables =  test.mapToPair(p-&gt;</span><br><span class="line">            new  Tuple2&lt;&gt;(model.predict(p.features()),p.label())</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>这里，采用了test部分的数据每一行都分为标签label和特征features，然后利用map方法，对每一行的数据进行model.predict(features)操作，获得预测值。并把预测值和真正的标签放到predictionAndLabels中。我们可以打印出具体的结果数据来看一下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">(0.0,0.0)</span><br><span class="line">(0.0,0.0)</span><br><span class="line">(0.0,0.0)</span><br><span class="line">(0.0,0.0)</span><br><span class="line">(0.0,0.0)</span><br><span class="line">(0.0,0.0)</span><br><span class="line">(0.0,0.0)</span><br><span class="line">(0.0,0.0)</span><br><span class="line">(0.0,0.0)</span><br><span class="line">(0.0,0.0)</span><br><span class="line">(0.0,0.0)</span><br><span class="line">(0.0,0.0)</span><br><span class="line">(0.0,0.0)</span><br><span class="line">(0.0,0.0)</span><br><span class="line">(0.0,0.0)</span><br><span class="line">(0.0,0.0)</span><br><span class="line">(0.0,0.0)</span><br><span class="line">(0.0,0.0)</span><br><span class="line">(1.0,1.0)</span><br><span class="line">(1.0,1.0)</span><br><span class="line">(1.0,1.0)</span><br><span class="line">(1.0,1.0)</span><br><span class="line">(1.0,1.0)</span><br><span class="line">(1.0,1.0)</span><br><span class="line">(1.0,1.0)</span><br><span class="line">(1.0,1.0)</span><br><span class="line">(2.0,1.0)</span><br><span class="line">(1.0,1.0)</span><br><span class="line">(1.0,1.0)</span><br><span class="line">(1.0,1.0)</span><br><span class="line">(1.0,1.0)</span><br><span class="line">(1.0,1.0)</span><br><span class="line">(1.0,1.0)</span><br><span class="line">(1.0,1.0)</span><br><span class="line">(2.0,2.0)</span><br><span class="line">(2.0,2.0)</span><br><span class="line">(2.0,2.0)</span><br><span class="line">(2.0,2.0)</span><br><span class="line">(2.0,2.0)</span><br><span class="line">(2.0,2.0)</span><br><span class="line">(2.0,2.0)</span><br><span class="line">(2.0,2.0)</span><br><span class="line">(2.0,2.0)</span><br><span class="line">(2.0,2.0)</span><br><span class="line">(2.0,2.0)</span><br><span class="line">(1.0,2.0)</span><br><span class="line">(2.0,2.0)</span><br><span class="line">(2.0,2.0)</span><br><span class="line">(2.0,2.0)</span><br><span class="line">(2.0,2.0)</span><br><span class="line">(2.0,2.0)</span><br><span class="line">(2.0,2.0)</span><br></pre></td></tr></table></figure><p>可以看出，大部分的预测是对的。其中(2.0,1.0)，(1.0,2.0)的预测与实际标签不同。</p><h2 id="5-3、模型评估"><a href="#5-3、模型评估" class="headerlink" title="5.3、模型评估"></a><strong>5.3、模型评估</strong></h2><p>模型预测的准确性打印：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//准确性打印：</span><br><span class="line">metrics:0.9615384615384616</span><br></pre></td></tr></table></figure><p><strong>参考资料</strong></p><ul><li><a href="http://spark.apache.org/docs/latest/mllib-linear-methods.html#logistic-regression" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/mllib-linear-methods.html#logistic-regression</a></li></ul></div><footer><div class="categories"><a href="/categories/machinelearning/">机器学习</a></div><div class="tags"><a href="/tags/content/">content</a>, <a href="/tags/machine-learning/">machine learning</a></div><div class="addthis addthis_toolbox addthis_default_style"><a class="addthis_button_facebook_like" fb:like:layout="button_count"></a> <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a> <a class="addthis_counter addthis_pill_style"></a></div><script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script><div class="clearfix"></div></footer></div></article><section id="comment"><h1 class="title">留言</h1><div id="fb-root"></div><script>!function(e,t,n){var a,c=e.getElementsByTagName(t)[0];e.getElementById(n)||((a=e.createElement(t)).id=n,a.src="//connect.facebook.net/en_US/all.js#xfbml=1&appId=123456789012345",c.parentNode.insertBefore(a,c))}(document,"script","facebook-jssdk")</script><div class="fb-comments" data-href="http://www.wangpengcufe.com/machinelearning/ml-ml5/index.html" data-num-posts="5" data-width="840" data-colorscheme="light"></div></section></div></div><aside id="sidebar" class="alignright"><script language="javascript">function search(e){return e.method="get",e.action="http://www.baidu.com/baidu",document.search_form.word.value=document.search_form.word.value,!0}</script><div class="search"><form name="search_form" target="_blank" onsubmit="search(this)"><input type="search" name="word" results="0" placeholder="百度站内搜索" onblur='this.value=""'></form></div><div class="widget tag"><h3 class="title">分类</h3><ul class="entry"><li><a href="/categories/read/">read</a><small>63</small></li><li><a href="/categories/tools/">工具</a><small>2</small></li><li><a href="/categories/machinelearning/">机器学习</a><small>13</small></li><li><a href="/categories/navigate/">菜单导航</a><small>1</small></li><li><a href="/categories/datadownload/">资料下载</a><small>1</small></li></ul></div><div class="widget tag"><h3 class="title">标签</h3><ul class="entry"><li><a href="/tags/content/">content</a><small>77</small></li><li><a href="/tags/library/">library</a><small>1</small></li><li><a href="/tags/machine-learning/">machine learning</a><small>13</small></li><li><a href="/tags/navigate/">navigate</a><small>1</small></li><li><a href="/tags/tools/">tools</a><small>2</small></li></ul></div><div class="widget tag"><h3 class="title">友情链接</h3><ul class="entry"><li><a href="http://blog.didispace.com" title="程序员DD">程序员DD</a></li><li><a href="https://mangoroom.cn" title="芒果的个人博客">芒果的个人博客</a></li><li><a href="http://www.baimin.com" target="_blank">百鸣网站百科</a></li><li><a href="http://blog.sina.com.cn/u/2435344920" target="_blank">默默读书</a></li><li><a href="https://www.jianshu.com/u/510007ddad06" target="_blank">王小鹏的随笔</a></li><li><a href="https://me.csdn.net/weixin_42438712" target="_blank">wangpengcufe的csdn博客</a></li><li><a href="http://meixiaohan.com/" target="_blank">小寒大人的blog</a></li></ul></div></aside><div class="clearfix"></div></div><footer id="footer" class="inner"><div class="alignleft">&copy; 2019 王小鹏 京ICP备19037345号-1</div><div class="clearfix"></div><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></footer><script src="//ajax.useso.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script><script src="/js/jquery.imagesloaded.min.js"></script><script src="/js/gallery.js"></script><link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css"><script src="/fancybox/jquery.fancybox.pack.js"></script><script type="text/javascript">jQuery(".fancybox").fancybox()</script></body></html>