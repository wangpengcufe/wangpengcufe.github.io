<!DOCTYPE HTML><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta name="baidu-site-verification" content="kZmc8XTvrB"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?458cfc1440d057b6b8799400c6b2e2bf";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><meta charset="utf-8"><title>python机器学习（四）分类算法-决策树 | 机器学习 and 数据科学</title><meta name="author" content="王小鹏  京ICP备19037345号-1"><meta name="keywords" content="机器学习,分类算法,决策树 PDF电子书下载,电子书，PDF下载"><meta name="description" content="PDF电子书下载,电子书，PDF下载"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta property="og:title" content="python机器学习（四）分类算法-决策树"><meta property="og:site_name" content="机器学习 and 数据科学"><meta property="og:image" content><link href="/favicon.png" rel="icon"><link rel="alternate" href="/atom.xml" title="机器学习 and 数据科学" type="application/atom+xml"><link rel="stylesheet" href="/css/style.css" media="screen" type="text/css"><!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]--></head><body><header id="header" class="inner"><div class="alignleft"><h1><a href="/">机器学习 and 数据科学</a></h1><h2><a href="/">明天幸福今天修</a></h2></div><nav id="main-nav" class="alignright"><ul><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/about">关于</a></li></ul><div class="clearfix"></div></nav><div class="clearfix"></div></header><div id="content" class="inner"><div id="main-col" class="alignleft"><div id="wrapper"><article id="post-pythonml-pythonml4" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting"><div class="post-content"><header><div class="icon"></div><time class="dt-published" datetime="2020-02-17T16:00:16.000Z"><a href="/machinelearning/pythonml-pythonml4/">2020-02-18</a><span id="busuanzi_container_page_pv"> &nbsp;&nbsp;&nbsp;&nbsp;阅读 <span id="busuanzi_value_page_pv"></span></span></time><h1 class="p-name title" itemprop="headline name">python机器学习（四）分类算法-决策树</h1></header><div class="e-content entry" itemprop="articleBody"><p><img src="http://wangpengcufe.com/pythonml4.1.png" alt="决策树"></p><h1 id="一、决策树的原理"><a href="#一、决策树的原理" class="headerlink" title="一、决策树的原理"></a>一、决策树的原理</h1><p>决策树思想的来源非常朴素，程序设计中的条件分支结构就是if-then结构，最早的决策树就是利用这类结构分割数据的一种分类学习方法 。</p><h1 id="二、决策树的现实案例"><a href="#二、决策树的现实案例" class="headerlink" title="二、决策树的现实案例"></a>二、决策树的现实案例</h1><h3 id="相亲"><a href="#相亲" class="headerlink" title="相亲"></a><strong>相亲</strong></h3><p><img src="http://wangpengcufe.com/pythonml4.2.png" alt="相亲决策树"></p><p>女儿：多大年纪了？<br>母亲：26。<br>女儿：长的帅不帅？<br>母亲：挺帅的。<br>女儿：收入高不？<br>母亲：不算很高，中等情况。<br>女儿：是公务员不？<br>母亲：是，在税务局上班呢。<br>女儿：那好，我去见见。</p><h3 id="银行是否发放贷款"><a href="#银行是否发放贷款" class="headerlink" title="银行是否发放贷款"></a><strong>银行是否发放贷款</strong></h3><p>行长：是否有自己的房子？<br>职员：有。<br>行长：可以考虑放贷。<br>职员：如果没有自己的房子呢？<br>行长：是否有稳定工作？<br>职员：有。<br>行长：可以考虑放贷。<br>职员：那如果没有呢？<br>行长：既没有自己的房子，也没有稳定工作，那咱还放啥贷款？<br>职员：懂了。<br><img src="http://wangpengcufe.com/pythonml4.3.png" alt="贷款决策树"></p><h3 id="预测足球队是否夺冠"><a href="#预测足球队是否夺冠" class="headerlink" title="预测足球队是否夺冠"></a><strong>预测足球队是否夺冠</strong></h3><p><img src="http://wangpengcufe.com/pythonml4.4.png" alt="预测决策树"></p><h1 id="三、信息论基础"><a href="#三、信息论基础" class="headerlink" title="三、信息论基础"></a>三、信息论基础</h1><h3 id="信息熵："><a href="#信息熵：" class="headerlink" title="信息熵："></a><strong>信息熵：</strong></h3><p>假如我们竞猜32只足球队谁是冠军？我可以把球编上号，从1到32，然后提问：冠 军在1-16号吗？依次进行二分法询问，只需要五次，就可以知道结果。<br>32支球队，问询了5次，信息量定义为5比特，log32=5比特。比特就是表示信息的单位。<br>假如有64支球队的话，那么我们需要二分法问询6次，信息量就是6比特，log64=6比特。<br>问询了多少次，专业术语称之为信息熵，单位为比特。<br>公式为：<br><img src="http://wangpengcufe.com/pythonml4.6.png" alt="信息熵"></p><p>信息熵的作用：<br>决策树生成的过程中，信息熵大的作为根节点，信息熵小的作为叶子节点，按照信息熵的从大到小原则，生成决策树。</p><h3 id="条件熵："><a href="#条件熵：" class="headerlink" title="条件熵："></a><strong>条件熵：</strong></h3><p>条件熵H（D|A）表示在已知随机变量A的条件下随机变量D的不确定性。<br>公式为：<br><img src="http://wangpengcufe.com/pythonml4.7.png" alt="条件熵"></p><p>通俗来讲就是，知道A情况下，D的信息量。</p><h3 id="信息增益："><a href="#信息增益：" class="headerlink" title="信息增益："></a><strong>信息增益：</strong></h3><p>特征A对训练数据集D的信息增益g(D,A),定义为集合D的信息熵H(D)与特征A给定条件下D的信息条件熵H(D|A)之差。<br>公式为：<br><img src="http://wangpengcufe.com/pythonml4.8.png" alt="信息增益"></p><p>怎么理解信息增益呢？信息增益表示得知特征X的信息而使得类Y的信息的不确定性减少的程度。简单讲，就是知道的增多，使得不知道的（不确定的）就减少。</p><h1 id="四、-决策树API"><a href="#四、-决策树API" class="headerlink" title="四、 决策树API"></a>四、 决策树API</h1><p>sklearn.tree.DecisionTreeClassifier</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">class sklearn.tree.DecisionTreeClassifier(criterion=’gini’, max_depth=None,random_state=None)</span><br><span class="line">决策树分类器</span><br><span class="line">criterion:默认是’gini’系数，也可以选择信息增益的熵’entropy’</span><br><span class="line">max_depth:树的深度大小</span><br><span class="line">random_state:随机数种子</span><br><span class="line"></span><br><span class="line">method:</span><br><span class="line">dec.fit(X,y): 根据数据集(X,y)建立决策树分类器</span><br><span class="line">dec.apply(X): 返回每个样本被预测为的叶子的索引。</span><br><span class="line">dec.cost_complexity_pruning_path(X,y): 在最小成本复杂性修剪期间计算修剪路径。</span><br><span class="line">dec.decision_path(X): 返回树中的决策路径</span><br><span class="line">dec.get_depth(): 返回树的深度</span><br><span class="line">dec.get_n_leaves(): 返回决策树的叶子节点</span><br><span class="line">dec.get_params(): 返回评估器的参数</span><br><span class="line">dec.predict(X): 预测X的类或回归值</span><br><span class="line">dec.predict_log_proba(X): 预测X的类的log值</span><br><span class="line">dec.predict_proba(X): 预测X分类的概率值</span><br><span class="line">dec.score(X,y): 测试数据X和标签值y之间的平均准确率</span><br><span class="line">dec.set_params(min_samples_split=3): 设置评估器的参数</span><br><span class="line">X 表示训练集，y表示特征值</span><br></pre></td></tr></table></figure><h1 id="五、-决策树的生成与本地保存"><a href="#五、-决策树的生成与本地保存" class="headerlink" title="五、 决策树的生成与本地保存"></a>五、 决策树的生成与本地保存</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.tree import DecisionTreeClassifier</span><br><span class="line">from sklearn.datasets import load_iris</span><br><span class="line">li = load_iris()</span><br><span class="line">dec = DecisionTreeClassifier()</span><br><span class="line"># 根据训练集(X,y)建立决策树分类器</span><br><span class="line">dec.fit(li.data,li.target)</span><br><span class="line"># 预测X的类或回归值</span><br><span class="line">dec.predict(li.data)</span><br><span class="line"># 测试数据X和标签值y之间的平均准确率</span><br><span class="line">dec.score(li.data,li.target)</span><br><span class="line"># 保存树文件 tree.dot</span><br><span class="line">tree.export_graphviz(dec,out_file=&apos;tree.dot&apos;)</span><br></pre></td></tr></table></figure><p>tree.dot 保存结果:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">digraph Tree &#123;</span><br><span class="line">node [shape=box] ;</span><br><span class="line">0 [label=&quot;X[2] &lt;= 2.45\ngini = 0.667\nsamples = 150\nvalue = [50, 50, 50]&quot;] ;</span><br><span class="line">1 [label=&quot;gini = 0.0\nsamples = 50\nvalue = [50, 0, 0]&quot;] ;</span><br><span class="line">.....</span><br></pre></td></tr></table></figure><h1 id="六、-决策树的优缺点"><a href="#六、-决策树的优缺点" class="headerlink" title="六、 决策树的优缺点"></a>六、 决策树的优缺点</h1><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a><strong>优点</strong></h3><ul><li>简单的理解和解释，树木可视化。</li><li>需要很少的数据准备，其他技术通常需要数据归一化。</li></ul><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a><strong>缺点</strong></h3><ul><li>决策树学习者可以创建不能很好地推广数据的过于复杂的树，被称为过拟合。</li><li>决策树可能不稳定，因为数据的小变化可能会导致完全不同的树<br>被生成。</li></ul><h3 id="改进"><a href="#改进" class="headerlink" title="改进"></a><strong>改进</strong></h3><ul><li>减枝cart算法</li><li>随机森林</li></ul></div><footer><div class="categories"><a href="/categories/machinelearning/">机器学习</a></div><div class="tags"><a href="/tags/content/">content</a>, <a href="/tags/machine-learning/">machine learning</a></div><div class="addthis addthis_toolbox addthis_default_style"><a class="addthis_button_facebook_like" fb:like:layout="button_count"></a> <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a> <a class="addthis_counter addthis_pill_style"></a></div><script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script><div class="clearfix"></div></footer></div></article><section id="comment"><h1 class="title">留言</h1><div id="fb-root"></div><script>!function(e,t,n){var a,c=e.getElementsByTagName(t)[0];e.getElementById(n)||((a=e.createElement(t)).id=n,a.src="//connect.facebook.net/en_US/all.js#xfbml=1&appId=123456789012345",c.parentNode.insertBefore(a,c))}(document,"script","facebook-jssdk")</script><div class="fb-comments" data-href="http://www.wangpengcufe.com/machinelearning/pythonml-pythonml4/index.html" data-num-posts="5" data-width="840" data-colorscheme="light"></div></section></div></div><aside id="sidebar" class="alignright"><script language="javascript">function search(e){return e.method="get",e.action="http://www.baidu.com/baidu",document.search_form.word.value=document.search_form.word.value,!0}</script><div class="search"><form name="search_form" target="_blank" onsubmit="search(this)"><input type="search" name="word" results="0" placeholder="百度站内搜索" onblur='this.value=""'></form></div><div class="widget tag"><h3 class="title">分类</h3><ul class="entry"><li><a href="/categories/read/">read</a><small>65</small></li><li><a href="/categories/tools/">工具</a><small>3</small></li><li><a href="/categories/machinelearning/">机器学习</a><small>22</small></li><li><a href="/categories/navigate/">菜单导航</a><small>1</small></li><li><a href="/categories/datadownload/">资料下载</a><small>1</small></li></ul></div><div class="widget tag"><h3 class="title">标签</h3><ul class="entry"><li><a href="/tags/content/">content</a><small>89</small></li><li><a href="/tags/library/">library</a><small>1</small></li><li><a href="/tags/machine-learning/">machine learning</a><small>22</small></li><li><a href="/tags/navigate/">navigate</a><small>1</small></li><li><a href="/tags/tools/">tools</a><small>3</small></li></ul></div><div class="widget tag"><h3 class="title">友情链接</h3><ul class="entry"><li><a href="http://blog.didispace.com" title="程序员DD">程序员DD</a></li><li><a href="https://mangoroom.cn" title="芒果的个人博客">芒果的个人博客</a></li><li><a href="http://www.baimin.com" target="_blank">百鸣网站百科</a></li><li><a href="http://blog.sina.com.cn/u/2435344920" target="_blank">默默读书</a></li><li><a href="https://www.jianshu.com/u/510007ddad06" target="_blank">王小鹏的随笔（简书）</a></li><li><a href="https://me.csdn.net/weixin_42438712" target="_blank">机器学习（csdn博客）</a></li><li><a href="https://zhuanlan.zhihu.com/c_1182309165824901120" target="_blank">机器学习（知乎）</a></li><li><a href="http://meixiaohan.com/" target="_blank">小寒大人的blog</a></li><li><a href="https://baippt.com/" target="_blank">ppt模板免费下载</a></li><li><a href="http://www.youneedcn.com/" target="_blank">你要的资源</a></li></ul></div></aside><div class="clearfix"></div></div><footer id="footer" class="inner"><div class="alignleft">&copy; 2020 王小鹏 京ICP备19037345号-1</div><div class="clearfix"></div><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></footer><script src="//ajax.useso.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script><script src="/js/jquery.imagesloaded.min.js"></script><script src="/js/gallery.js"></script><link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css"><script src="/fancybox/jquery.fancybox.pack.js"></script><script type="text/javascript">jQuery(".fancybox").fancybox()</script></body></html>