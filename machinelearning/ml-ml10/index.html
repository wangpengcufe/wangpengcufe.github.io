<!DOCTYPE HTML><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta name="baidu-site-verification" content="kZmc8XTvrB"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?458cfc1440d057b6b8799400c6b2e2bf";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><meta charset="utf-8"><title>机器学习（十） 聚类 | 机器学习 and 数据科学</title><meta name="author" content="王小鹏  京ICP备19037345号-1"><meta name="description" content="机器学习 王鹏 数据科学"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta property="og:title" content="机器学习（十） 聚类"><meta property="og:site_name" content="机器学习 and 数据科学"><meta property="og:image" content><link href="/favicon.png" rel="icon"><link rel="alternate" href="/atom.xml" title="机器学习 and 数据科学" type="application/atom+xml"><link rel="stylesheet" href="/css/style.css" media="screen" type="text/css"><!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]--></head><body><header id="header" class="inner"><div class="alignleft"><h1><a href="/">机器学习 and 数据科学</a></h1><h2><a href="/">明天幸福今天修</a></h2></div><nav id="main-nav" class="alignright"><ul><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/about">关于</a></li></ul><div class="clearfix"></div></nav><div class="clearfix"></div></header><div id="content" class="inner"><div id="main-col" class="alignleft"><div id="wrapper"><article id="post-ml-ml10" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting"><div class="post-content"><header><div class="icon"></div><time class="dt-published" datetime="2019-11-14T11:35:05.000Z"><a href="/machinelearning/ml-ml10/">2019-11-14</a><span id="busuanzi_container_page_pv"> &nbsp;&nbsp;&nbsp;&nbsp;阅读 <span id="busuanzi_value_page_pv"></span></span></time><h1 class="p-name title" itemprop="headline name">机器学习（十） 聚类</h1></header><div class="e-content entry" itemprop="articleBody"><p>标签： machine learning</p><p><img src="http://wangpengcufe.com/ml10.png" alt="目录"></p><a id="more"></a><h1 id="一、概念"><a href="#一、概念" class="headerlink" title="一、概念"></a><strong>一、概念</strong></h1><h3 id="1-1、定义"><a href="#1-1、定义" class="headerlink" title="1.1、定义"></a><strong>1.1、定义</strong></h3><p>按照某一个特定的标准（比如距离），把一个数据集分割成不同的类或簇，使得同一个簇内的数据对象的相似性尽可能大，同时不再同一个簇内的数据对象的差异性也尽可能的大。</p><p>聚类属于典型的无监督学习（Unsupervised Learning） 方法。与监督学习（如分类器）相比，无监督学习的训练集没有人为标注的结果。在非监督式学习中，数据并不被特别标识，学习模型是为了推断出数据的一些内在结构。</p><h3 id="1-2、主要方法"><a href="#1-2、主要方法" class="headerlink" title="1.2、主要方法"></a><strong>1.2、主要方法</strong></h3><p><strong>层次聚类（Hierarchical Clustering）</strong>：合并法、分解法、树状图</p><p><strong>非层次聚类</strong>：划分聚类、谱聚类</p><h3 id="1-3、主要特征"><a href="#1-3、主要特征" class="headerlink" title="1.3、主要特征"></a><strong>1.3、主要特征</strong></h3><ul><li>聚类变量的测量尺度不同，需要事先对变量标准化；</li><li>聚类变量中如果有些变量非常相关，意味着这个变量的权重会更大</li><li>欧式距离的平方是最常用的距离测量方法；</li><li>聚类算法要比距离测量方法对聚类结果影响更大；</li><li>标准化方法影响聚类模式：</li><li>变量标准化倾向产生基于数量的聚类；</li><li>样本标准化倾向产生基于模式的聚类；</li><li>一般聚类个数在4－6类，不易太多，或太少</li></ul><h1 id="二、KMeans原理"><a href="#二、KMeans原理" class="headerlink" title="二、KMeans原理"></a><strong>二、KMeans原理</strong></h1><p>KMeans 是一个迭代求解的聚类算法，其属于 划分（Partitioning） 型的聚类方法，即首先创建K个划分，然后迭代地将样本从一个划分转移到另一个划分来改善最终聚类的质量，KMeans 的过程大致如下：</p><p>1.根据给定的k值，选取k个样本点作为初始划分中心；</p><p>2.计算所有样本点到每一个划分中心的距离，并将所有样本点划分到距离最近的划分中心；</p><p>3.计算每个划分中样本点的平均值，将其作为新的中心；</p><p>4.用计算出的中心位置重新进行聚类，如此反复循环，直到达到最大迭代次数，或划分中心的变化小于某一预定义阈值</p><p>方法的特点：</p><ul><li>通常要求已知类别数</li><li>可人为指定初始位置</li><li>节省运算时间</li><li>样本量大于100时有必要考虑</li><li>只能使用连续性变量</li></ul><h1 id="三、代码实现"><a href="#三、代码实现" class="headerlink" title="三、代码实现"></a><strong>三、代码实现</strong></h1><h3 id="3-1、数据集的读取"><a href="#3-1、数据集的读取" class="headerlink" title="3.1、数据集的读取"></a><strong>3.1、数据集的读取</strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.spark.SparkConf;</span><br><span class="line">import org.apache.spark.api.java.JavaRDD;</span><br><span class="line">import org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line">import org.apache.spark.mllib.clustering.KMeans;</span><br><span class="line">import org.apache.spark.mllib.clustering.KMeansModel;</span><br><span class="line">import org.apache.spark.mllib.linalg.Vector;</span><br><span class="line">import org.apache.spark.mllib.linalg.Vectors;</span><br><span class="line">//1、获取Spark</span><br><span class="line">SparkConf conf = new SparkConf().setAppName(&quot;ClusteringModel&quot;).setMaster(&quot;local&quot;);</span><br><span class="line">JavaSparkContext sc = new JavaSparkContext(conf);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">//2、读取数据</span><br><span class="line">JavaRDD&lt;String&gt; rawData = sc.textFile(&quot;data/mllib/iris.data&quot;);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">JavaRDD&lt;Vector&gt; trainingData = rawData.map(line-&gt;&#123;</span><br><span class="line">    String[] parts = line.split(&quot;,&quot;);</span><br><span class="line">    return Vectors.dense(Double.parseDouble(parts[0]),</span><br><span class="line">            Double.parseDouble(parts[1]),</span><br><span class="line">            Double.parseDouble(parts[2]),</span><br><span class="line">            Double.parseDouble(parts[3]));</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>本文使用模式识别领域广泛使用的UCI数据集中的鸢尾花数据Iris进行实验，Iris数据的样本容量为150，有四个实数值的特征，分别代表花朵四个部位的尺寸，以及该样本对应鸢尾花的亚种类型（共有3种亚种类型）,如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">5.1,3.5,1.4,0.2,setosa</span><br><span class="line">...</span><br><span class="line">5.4,3.0,4.5,1.5,versicolor</span><br><span class="line">...</span><br><span class="line">7.1,3.0,5.9,2.1,virginica</span><br><span class="line">...</span><br></pre></td></tr></table></figure><h3 id="3-2、模型训练与分析"><a href="#3-2、模型训练与分析" class="headerlink" title="3.2、模型训练与分析"></a><strong>3.2、模型训练与分析</strong></h3><p>可以通过创建一个KMeans类并调用其run(RDD[Vector])方法来训练一个KMeans模型KMeansModel，在该方法调用前需要设置一系列参数，如下表所示：</p><p>| 参数 | 含义 |<br>| ——————- | :———————: |<br>| K | 聚类数目，默认为2 |<br>| maxIterations | 最大迭代次数，默认为20 |<br>| initializationMode | 初始化模式，默认为”k-means||” |<br>| runs | 运行次数，默认为：1 |<br>| initializationSteps | 初始化步数，用于KMeans||，默认为5 |<br>| epsilon | 迭代停止的阈值，默认为1e-4 |</p><p>其中，每一个参数均可通过名为setXXX(…)（如maxIterations即为setMaxIterations()）的方法进行设置。<br>由于KMeans类只有无参的构造函数，其对象创建、参数设置需要分别进行，且往往使用的只有存放模型的KMeansModel类对象，花功夫创建出的KMeans类自象本身却并未使用。故MLlib也提供了包装好的高层次方法KMeans.train(…)，传入训练样本和相应的参数，即返回一个训练好的KMeansModel对象，十分方便。<br>该方法有4个重载形式，分别可以指定不同的输入参数，具体可以查阅MLlib的API文档，这里我们使用KMeans.train(data, k, maxIterations, runs)形式，只需要输入k值、最大迭代次数和运行次数，其他参数使用默认值，如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">KMeansModel model = KMeans.train(trainingData.rdd(),3,100,5);</span><br><span class="line">//通过KMeansModel类自带的clusterCenters属性获取到模型的所有聚类中心情况</span><br></pre></td></tr></table></figure><p>这样，模型即创建成功了。可以通过KMeansModel类自带的clusterCenters属性获取到模型的所有聚类中心情况：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Vector[] vectors = model.clusterCenters();</span><br><span class="line">for(Vector vector : vectors) &#123;</span><br><span class="line">    System.out.println(vector);</span><br><span class="line">&#125;</span><br><span class="line">/**</span><br><span class="line">*控制台输出结果：</span><br><span class="line">----------------------------------------------------------------------------</span><br><span class="line">[5.901612903225807,2.748387096774194,4.393548387096774,1.4338709677419355]2</span><br><span class="line">[5.005999999999999,3.4180000000000006,1.4640000000000002,0.2439999999999999]</span><br><span class="line">[6.85,3.0736842105263147,5.742105263157893,2.071052631578947]</span><br><span class="line">----------------------------------------------------------------------------</span><br><span class="line">**/</span><br></pre></td></tr></table></figure><p>也可以通过predict()方法来确定每个样本所属的聚类：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">//通过predict()方法来确定每个样本所属的聚类:</span><br><span class="line">trainingData.collect().forEach(sample-&gt;&#123;</span><br><span class="line">    int predictedClustre = model.predict(sample);</span><br><span class="line">    System.out.println(sample.toString()+&quot; belongs to cluster &quot;+predictedClustre);</span><br><span class="line">&#125;);</span><br><span class="line">/**</span><br><span class="line">*控制台输出结果：</span><br><span class="line">---------------------------------------</span><br><span class="line">[5.1,3.5,1.4,0.2] belongs to cluster 1</span><br><span class="line">[4.9,3.0,1.4,0.2] belongs to cluster 1</span><br><span class="line">[4.7,3.2,1.3,0.2] belongs to cluster 1</span><br><span class="line">[4.6,3.1,1.5,0.2] belongs to cluster 1</span><br><span class="line">[5.0,3.6,1.4,0.2] belongs to cluster 1</span><br><span class="line">[5.4,3.9,1.7,0.4] belongs to cluster 1</span><br><span class="line">[4.6,3.4,1.4,0.3] belongs to cluster 1</span><br><span class="line"> .....</span><br><span class="line">--------------------------------------</span><br><span class="line">**/</span><br></pre></td></tr></table></figure><p>同时，KMeansModel类还提供了计算 集合内误差平方和（Within Set Sum of Squared Error, WSSSE) 的方法来度量聚类的有效性：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">double wssse = model.computeCost(trainingData.rdd());</span><br><span class="line">System.out.println(&quot;集合内误差平方和：&quot;+wssse);</span><br><span class="line">/**</span><br><span class="line">*控制台输出结果：</span><br><span class="line">----------------------------------</span><br><span class="line">集合内误差平方和：78.94084142614648</span><br><span class="line">----------------------------------</span><br><span class="line">**/</span><br></pre></td></tr></table></figure><h1 id="四、主要应用"><a href="#四、主要应用" class="headerlink" title="四、主要应用"></a><strong>四、主要应用</strong></h1><h3 id="4-1、商业"><a href="#4-1、商业" class="headerlink" title="4.1、商业"></a><strong>4.1、商业</strong></h3><p>聚类分析被用来发现不同的客户群，并且通过购买模式刻画不同的客户群的特征。<br>聚类分析是细分市场的有效工具，同时也可用于研究消费者行为，寻找新的潜在市场、选择实验的市场，并作为多元分析的预处理。</p><h3 id="4-2、生物"><a href="#4-2、生物" class="headerlink" title="4.2、生物"></a><strong>4.2、生物</strong></h3><p>聚类分析被用来动植物分类和对基因进行分类，获取对种群固有结构的认识</p><h3 id="4-3、地理"><a href="#4-3、地理" class="headerlink" title="4.3、地理"></a><strong>4.3、地理</strong></h3><p>聚类能够帮助在地球中被观察的数据库商趋于的相似性</p><h3 id="4-4、保险行业"><a href="#4-4、保险行业" class="headerlink" title="4.4、保险行业"></a><strong>4.4、保险行业</strong></h3><p>聚类分析通过一个高的平均消费来鉴定汽车保险单持有者的分组，同时根据住宅类型，价值，地理位置来鉴定一个城市的房产分组</p><h3 id="4-5、因特网"><a href="#4-5、因特网" class="headerlink" title="4.5、因特网"></a><strong>4.5、因特网</strong></h3><p>聚类分析被用来在网上进行文档归类来修复信息</p><h3 id="4-6、电子商务"><a href="#4-6、电子商务" class="headerlink" title="4.6、电子商务"></a><strong>4.6、电子商务</strong></h3><p>聚类分析在电子商务中网站建设数据挖掘中也是很重要的一个方面，通过分组聚类出具有相似浏览行为的客户，并分析客户的共同特征，可以更好的帮助电子商务的用户了解自己的客户，向客户提供更合适的服务。</p><p><strong>参考资料：</strong><a href="http://spark.apache.org/docs/latest/mllib-clustering.html" title="http://spark.apache.org/docs/latest/mllib-clustering.html" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/mllib-clustering.html</a></p><p><strong>数据下载：</strong><a href="http://wangpengcufe.com/iris.data" title="http://wangpengcufe.com/iris.data" target="_blank" rel="noopener">http://wangpengcufe.com/iris.data</a></p></div><footer><div class="categories"><a href="/categories/machinelearning/">机器学习</a></div><div class="tags"><a href="/tags/content/">content</a>, <a href="/tags/machine-learning/">machine learning</a></div><div class="addthis addthis_toolbox addthis_default_style"><a class="addthis_button_facebook_like" fb:like:layout="button_count"></a> <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a> <a class="addthis_counter addthis_pill_style"></a></div><script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script><div class="clearfix"></div></footer></div></article><section id="comment"><h1 class="title">留言</h1><div id="fb-root"></div><script>!function(e,t,n){var a,c=e.getElementsByTagName(t)[0];e.getElementById(n)||((a=e.createElement(t)).id=n,a.src="//connect.facebook.net/en_US/all.js#xfbml=1&appId=123456789012345",c.parentNode.insertBefore(a,c))}(document,"script","facebook-jssdk")</script><div class="fb-comments" data-href="http://wangpengcufe.github.io/machinelearning/ml-ml10/index.html" data-num-posts="5" data-width="840" data-colorscheme="light"></div></section></div></div><aside id="sidebar" class="alignright"><script language="javascript">function search(e){return e.method="get",e.action="http://www.baidu.com/baidu",document.search_form.word.value=document.search_form.word.value,!0}</script><div class="search"><form name="search_form" target="_blank" onsubmit="search(this)"><input type="search" name="word" results="0" placeholder="百度站内搜索" onblur='this.value=""'></form></div><div class="widget tag"><h3 class="title">分类</h3><ul class="entry"><li><a href="/categories/read/">read</a><small>54</small></li><li><a href="/categories/tools/">工具</a><small>2</small></li><li><a href="/categories/machinelearning/">机器学习</a><small>13</small></li><li><a href="/categories/navigate/">菜单导航</a><small>1</small></li><li><a href="/categories/read/navigate/">菜单导航</a><small>1</small></li></ul></div><div class="widget tag"><h3 class="title">标签</h3><ul class="entry"><li><a href="/tags/content/">content</a><small>68</small></li><li><a href="/tags/machine-learning/">machine learning</a><small>13</small></li><li><a href="/tags/navigate/">navigate</a><small>2</small></li><li><a href="/tags/tools/">tools</a><small>2</small></li></ul></div><div class="widget tag"><h3 class="title">友情链接</h3><ul class="entry"><li><a href="http://blog.didispace.com" title="程序员DD">程序员DD</a></li><li><a href="https://mangoroom.cn" title="芒果的个人博客">芒果的个人博客</a></li><li><a href="http://www.baimin.com" target="_blank">百鸣网站百科</a></li><li><a href="http://blog.sina.com.cn/u/2435344920" target="_blank">默默读书</a></li></ul></div></aside><div class="clearfix"></div></div><footer id="footer" class="inner"><div class="alignleft">&copy; 2019 王小鹏 京ICP备19037345号-1</div><div class="clearfix"></div><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></footer><script src="//ajax.useso.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script><script src="/js/jquery.imagesloaded.min.js"></script><script src="/js/gallery.js"></script><link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css"><script src="/fancybox/jquery.fancybox.pack.js"></script><script type="text/javascript">jQuery(".fancybox").fancybox()</script></body></html>