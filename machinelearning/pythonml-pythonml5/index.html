<!DOCTYPE HTML><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta name="baidu-site-verification" content="kZmc8XTvrB"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?458cfc1440d057b6b8799400c6b2e2bf";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><meta charset="utf-8"><title>python机器学习（五）回归算法-线性回归 | 机器学习 and 数据科学</title><meta name="author" content="王小鹏  京ICP备19037345号-1"><meta name="keywords" content="机器学习,回归算法,线性回归 PDF电子书下载,电子书，PDF下载"><meta name="description" content="PDF电子书下载,电子书，PDF下载"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta property="og:title" content="python机器学习（五）回归算法-线性回归"><meta property="og:site_name" content="机器学习 and 数据科学"><meta property="og:image" content><link href="/favicon.png" rel="icon"><link rel="alternate" href="/atom.xml" title="机器学习 and 数据科学" type="application/atom+xml"><link rel="stylesheet" href="/css/style.css" media="screen" type="text/css"><!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]--></head><body><header id="header" class="inner"><div class="alignleft"><h1><a href="/">机器学习 and 数据科学</a></h1><h2><a href="/">明天幸福今天修</a></h2></div><nav id="main-nav" class="alignright"><ul><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/about">关于</a></li></ul><div class="clearfix"></div></nav><div class="clearfix"></div></header><div id="content" class="inner"><div id="main-col" class="alignleft"><div id="wrapper"><article id="post-pythonml-pythonml5" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting"><div class="post-content"><header><div class="icon"></div><time class="dt-published" datetime="2020-04-03T04:45:16.000Z"><a href="/machinelearning/pythonml-pythonml5/">2020-04-03</a><span id="busuanzi_container_page_pv"> &nbsp;&nbsp;&nbsp;&nbsp;阅读 <span id="busuanzi_value_page_pv"></span></span></time><h1 class="p-name title" itemprop="headline name">python机器学习（五）回归算法-线性回归</h1></header><div class="e-content entry" itemprop="articleBody"><p><img src="https://upload-images.jianshu.io/upload_images/7289495-d1d3209b329261b5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="线性回归"></p><h1 id="一、线性回归的概念"><a href="#一、线性回归的概念" class="headerlink" title="一、线性回归的概念"></a>一、线性回归的概念</h1><h5 id="1-1、定义"><a href="#1-1、定义" class="headerlink" title="1.1、定义"></a>1.1、定义</h5><p>线性回归通过一个或者多个自变量与因变量之间之间进行建模的回归分析。其中特点为一个或多个称为回归系数的模型参数的线性组合。</p><p><strong>优点：</strong><br>结果易于理解，计算不复杂。</p><p><strong>缺点：</strong><br>对非线性的数据拟合不好。</p><p><strong>适用数据类型：</strong><br>数值型和标称型。</p><h5 id="1-2、分类"><a href="#1-2、分类" class="headerlink" title="1.2、分类"></a>1.2、分类</h5><p><strong>一元线性回归：</strong><br>涉及到的变量只有一个。</p><p><strong>多元线性回归：</strong><br>涉及到的变量两个或两个以上。</p><h5 id="1-3、公式"><a href="#1-3、公式" class="headerlink" title="1.3、公式"></a>1.3、公式</h5><p><img src="https://upload-images.jianshu.io/upload_images/7289495-b6bdc1c15b09727c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><p>其中𝑤,𝑥为矩阵：<img src="https://upload-images.jianshu.io/upload_images/7289495-f414dd162c70aa41.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="𝑤,𝑥为矩阵"></p><h1 id="二、线性回归的实例"><a href="#二、线性回归的实例" class="headerlink" title="二、线性回归的实例"></a>二、线性回归的实例</h1><h5 id="2-1、单变量实例"><a href="#2-1、单变量实例" class="headerlink" title="2.1、单变量实例"></a>2.1、单变量实例</h5><p>房子价格与房子面积<br><img src="https://upload-images.jianshu.io/upload_images/7289495-b067cd091dbd501e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="单变量实例"></p><h5 id="2-2、多变量实例"><a href="#2-2、多变量实例" class="headerlink" title="2.2、多变量实例"></a>2.2、多变量实例</h5><p>期末成绩：0.7×考试成绩+0.3×平时成绩<br>西瓜好坏：0.2×色泽+0.5×根蒂+0.3×敲声<br><img src="https://upload-images.jianshu.io/upload_images/7289495-6ebb21fabea01890.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="多变量实例"></p><h1 id="三、损失函数"><a href="#三、损失函数" class="headerlink" title="三、损失函数"></a>三、损失函数</h1><p>损失函数是一个贯穿整个机器学习重要的一个概念，大部分机器学习算法都会有误差，我们得通过显性的公式来描述这个误差，并且将这个误差优化到最小值。</p><h5 id="3-1、损失原因"><a href="#3-1、损失原因" class="headerlink" title="3.1、损失原因"></a>3.1、损失原因</h5><p>预测结果与真实值是有一定的误差。<br><img src="https://upload-images.jianshu.io/upload_images/7289495-a3aff1dc51b19aef.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="损失函数"></p><h5 id="3-2、损失函数定义"><a href="#3-2、损失函数定义" class="headerlink" title="3.2、损失函数定义"></a>3.2、损失函数定义</h5><p>损失函数代表了误差的大小，用公式表示如下：<br><img src="https://upload-images.jianshu.io/upload_images/7289495-b0a531bf9ded4567.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="损失函数公式"><br>又称最小二乘法。</p><p>对于线性回归模型，将模型与数据点之间的距离差之和做为衡量匹配好坏的标准，误差越小,匹配程度越大。我们要找的模型就是需要将f(x)和我们的真实值之间最相似的状态。</p><p>损失函数由W决定，那么如何去求模型当中的W，使得损失最小？（目的是找到最小损失对应的W值）<br><img src="https://upload-images.jianshu.io/upload_images/7289495-f014a751a711bb4b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="减少损失函数"></p><h5 id="3-3、减小损失函数的2种方式"><a href="#3-3、减小损失函数的2种方式" class="headerlink" title="3.3、减小损失函数的2种方式"></a>3.3、减小损失函数的2种方式</h5><h5 id="方式一：最小二乘法之正规方程"><a href="#方式一：最小二乘法之正规方程" class="headerlink" title="方式一：最小二乘法之正规方程"></a>方式一：最小二乘法之正规方程</h5><p>求解：<img src="https://upload-images.jianshu.io/upload_images/7289495-08e115ff92b3edac.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="最小二乘法之正规方程"><br>𝑋为特征值矩阵，𝑦为目标值矩阵。<br><img src="https://upload-images.jianshu.io/upload_images/7289495-2e5f7ac946294576.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="损失函数直观图"></p><p>缺点：当特征过于复杂，求解速度太慢。<br>对于复杂的算法，不能使用正规方程求解(逻辑回归等)</p><h5 id="方式二：最小二乘法之梯度下降"><a href="#方式二：最小二乘法之梯度下降" class="headerlink" title="方式二：最小二乘法之梯度下降"></a>方式二：最小二乘法之梯度下降</h5><p><img src="https://upload-images.jianshu.io/upload_images/7289495-a5b09f063fb5bc58.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"><br>𝛼为学习速率，需要手动指定，其中<img src="https://upload-images.jianshu.io/upload_images/7289495-020e33036a96e5ca.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="方向">表示方向<br>理解：沿着这个函数下降的方向找，最后就能找到山谷的最低点，然后<br>更新W值<br><img src="https://upload-images.jianshu.io/upload_images/7289495-b69d8b234bc83dff.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="最小二乘法之梯度下降"><br><img src="https://upload-images.jianshu.io/upload_images/7289495-aff3601d6c5c14ef.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="最小二乘法之梯度下降"></p><h5 id="3-4、两种方式对比："><a href="#3-4、两种方式对比：" class="headerlink" title="3.4、两种方式对比："></a>3.4、两种方式对比：</h5><p><img src="https://upload-images.jianshu.io/upload_images/7289495-dd802975efddca68.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="两种方式对比"></p><h1 id="四、线性回归API"><a href="#四、线性回归API" class="headerlink" title="四、线性回归API"></a>四、线性回归API</h1><h5 id="4-1、普通最小二乘法线性回归"><a href="#4-1、普通最小二乘法线性回归" class="headerlink" title="4.1、普通最小二乘法线性回归"></a>4.1、普通最小二乘法线性回归</h5><p>sklearn.linear_model.LinearRegression()<br>coef_：回归系数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line">reg = LinearRegression()</span><br><span class="line"># 方法</span><br><span class="line">reg.fit(X,y,sample_weight = None)  #使用X作为训练数据拟合模型，y作为X的类别值。X，y为数组或者矩阵</span><br><span class="line"></span><br><span class="line">reg.predict([[X,y]])  # 预测提供的数据对应的结果</span><br><span class="line"> </span><br><span class="line">#属性</span><br><span class="line">reg.coef_   #表示回归系数w=(w1,w2....)</span><br></pre></td></tr></table></figure><h5 id="4-2、通过使用SGD最小线性模型"><a href="#4-2、通过使用SGD最小线性模型" class="headerlink" title="4.2、通过使用SGD最小线性模型"></a>4.2、通过使用SGD最小线性模型</h5><p>sklearn.linear_model.SGDRegressor( )<br>coef_：回归系数</p><h5 id="4-3、带有正则化的线性回归"><a href="#4-3、带有正则化的线性回归" class="headerlink" title="4.3、带有正则化的线性回归"></a>4.3、带有正则化的线性回归</h5><p>sklearn.linear_model.Ridge<br>具有l2正则化的线性最小二乘法<br>alpha:正则化力度<br>coef_:回归系数</p><h1 id="五、实现案例"><a href="#五、实现案例" class="headerlink" title="五、实现案例"></a>五、实现案例</h1><h5 id="波士顿房价数据分析流程"><a href="#波士顿房价数据分析流程" class="headerlink" title="波士顿房价数据分析流程:"></a>波士顿房价数据分析流程:</h5><h5 id="5-1、数据获取"><a href="#5-1、数据获取" class="headerlink" title="5.1、数据获取"></a>5.1、数据获取</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.datasets import load_boston</span><br><span class="line">from sklearn.linear_model import LinearRegression, SGDRegressor,  Ridge, LogisticRegression</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.metrics import mean_squared_error, classification_report</span><br><span class="line">from sklearn.externals import joblib</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line"># 获取数据</span><br><span class="line">lb = load_boston()</span><br></pre></td></tr></table></figure><h5 id="5-2、数据分割"><a href="#5-2、数据分割" class="headerlink" title="5.2、数据分割"></a>5.2、数据分割</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 分割数据集到训练集和测试集</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(lb.data, lb.target, test_size=0.25)</span><br></pre></td></tr></table></figure><h5 id="5-3、训练与测试数据标准化处理"><a href="#5-3、训练与测试数据标准化处理" class="headerlink" title="5.3、训练与测试数据标准化处理"></a>5.3、训练与测试数据标准化处理</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 特征值和目标值是都必须进行标准化处理, 实例化两个标准化API</span><br><span class="line">std_x = StandardScaler()</span><br><span class="line"></span><br><span class="line">x_train = std_x.fit_transform(x_train)</span><br><span class="line">x_test = std_x.transform(x_test)</span><br><span class="line"></span><br><span class="line"># 目标值</span><br><span class="line">std_y = StandardScaler()</span><br><span class="line"></span><br><span class="line">y_train = std_y.fit_transform(y_train)</span><br><span class="line">y_test = std_y.transform(y_test)</span><br></pre></td></tr></table></figure><h5 id="5-4、线性回归模型和梯度下降估计对房价进行预测"><a href="#5-4、线性回归模型和梯度下降估计对房价进行预测" class="headerlink" title="5.4、线性回归模型和梯度下降估计对房价进行预测"></a>5.4、线性回归模型和梯度下降估计对房价进行预测</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># 正规方程求解方式预测结果</span><br><span class="line">lr = LinearRegression()</span><br><span class="line">lr.fit(x_train, y_train)</span><br><span class="line">print(lr.coef_)</span><br><span class="line">保存训练好的模型</span><br><span class="line">joblib.dump(lr, &quot;test.pkl&quot;)</span><br><span class="line"># 预测测试集的房子价格</span><br><span class="line">y_lr_predict = std_y.inverse_transform(lr.predict(x_test))</span><br><span class="line">print(&quot;正规方程测试集里面每个房子的预测价格：&quot;, y_lr_predict)</span><br><span class="line">print(&quot;正规方程的均方误差：&quot;, mean_squared_error(std_y.inverse_transform(y_test), y_lr_predict))</span><br><span class="line"></span><br><span class="line"># 梯度下降进行房价预测</span><br><span class="line">sgd = SGDRegressor()</span><br><span class="line">sgd.fit(x_train, y_train)</span><br><span class="line">print(sgd.coef_)</span><br><span class="line"># 预测测试集的房子价格</span><br><span class="line">y_sgd_predict = std_y.inverse_transform(sgd.predict(x_test))</span><br><span class="line">print(&quot;梯度下降测试集里面每个房子的预测价格：&quot;, y_sgd_predict)</span><br><span class="line">print(&quot;梯度下降的均方误差：&quot;, mean_squared_error(std_y.inverse_transform(y_test), y_sgd_predict))</span><br><span class="line"></span><br><span class="line"># 岭回归进行房价预测</span><br><span class="line">rd = Ridge(alpha=1.0)</span><br><span class="line">rd.fit(x_train, y_train)</span><br><span class="line">print(rd.coef_)</span><br><span class="line"># 预测测试集的房子价格</span><br><span class="line">y_rd_predict = std_y.inverse_transform(rd.predict(x_test))</span><br><span class="line">print(&quot;梯度下降测试集里面每个房子的预测价格：&quot;, y_rd_predict)</span><br><span class="line">print(&quot;梯度下降的均方误差：&quot;, mean_squared_error(std_y.inverse_transform(y_test), y_rd_predict))</span><br></pre></td></tr></table></figure><h1 id="六、回归的性能评估"><a href="#六、回归的性能评估" class="headerlink" title="六、回归的性能评估"></a>六、回归的性能评估</h1><h5 id="6-1、均方差误差评估机制-（MSE）："><a href="#6-1、均方差误差评估机制-（MSE）：" class="headerlink" title="6.1、均方差误差评估机制 （MSE）："></a>6.1、均方差误差评估机制 （MSE）：</h5><p><img src="https://upload-images.jianshu.io/upload_images/7289495-aa60bf2ee9693f1d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="均方差误差评估机制"></p><p>注：𝑦^𝑖为预测值，¯𝑦为真实值。</p><h5 id="6-2、回归评估API："><a href="#6-2、回归评估API：" class="headerlink" title="6.2、回归评估API："></a>6.2、回归评估API：</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.mean_squared_error</span><br><span class="line">mean_squared_error(y_true, y_pred)</span><br><span class="line">均方误差回归损失</span><br><span class="line">y_true:真实值</span><br><span class="line">y_pred:预测值</span><br><span class="line">return:浮点数结果</span><br></pre></td></tr></table></figure><p>注：真实值，预测值为标准化之前的值。</p><h1 id="七、线性回归的可能问题"><a href="#七、线性回归的可能问题" class="headerlink" title="七、线性回归的可能问题"></a>七、线性回归的可能问题</h1><p>训练数据训练的很好啊，误差也不大，为什么在测试集上面有问题呢？机器学习可能存在过拟合和欠拟合的问题。如下图：<br><img src="https://upload-images.jianshu.io/upload_images/7289495-5fbb11953b73903f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="过拟合和欠拟合"></p><p><img src="https://upload-images.jianshu.io/upload_images/7289495-3f12dd3f1d9552ac.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="过拟合和欠拟合"></p><h5 id="7-1、过拟合"><a href="#7-1、过拟合" class="headerlink" title="7.1、过拟合"></a>7.1、过拟合</h5><p>一个假设在训练数据上能够获得比其他假设更好的拟合， 但是在训练数据外的数据集上却不能很好地拟合数据，此时认为这个假设出现了过拟合的现象。(模型过于复杂)，如下图：<br><img src="https://upload-images.jianshu.io/upload_images/7289495-6fd703cd43910634.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="过拟合"></p><h6 id="产生原因："><a href="#产生原因：" class="headerlink" title="产生原因："></a>产生原因：</h6><p>原始特征过多，存在一些嘈杂特征， 模型过于复杂是因为模型尝试去兼顾各个测试数据点。</p><h6 id="解决办法："><a href="#解决办法：" class="headerlink" title="解决办法："></a>解决办法：</h6><ul><li>进行特征选择，消除关联性大的特征（很难做）</li><li>交叉验证（建议使用）</li><li>正则化 （了解即可）</li></ul><h4 id="7-2、欠拟合"><a href="#7-2、欠拟合" class="headerlink" title="7.2、欠拟合"></a>7.2、欠拟合</h4><p>一个假设在训练数据上不能获得更好的拟合， 但是在训练数据外的数据集上也不能很好地拟合数据，此时认为这个假设出现了欠拟合的现象。(模型过于简单)。如下图：<br><img src="https://upload-images.jianshu.io/upload_images/7289495-6407b29f79f29e1b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="欠拟合"></p><h6 id="产生原因：-1"><a href="#产生原因：-1" class="headerlink" title="产生原因："></a>产生原因：</h6><p>学习到数据的特征过少。</p><h6 id="解决办法：-1"><a href="#解决办法：-1" class="headerlink" title="解决办法："></a>解决办法：</h6><p>增加数据的特征数量。</p></div><footer><div class="categories"><a href="/categories/machinelearning/">机器学习</a></div><div class="tags"><a href="/tags/content/">content</a>, <a href="/tags/machine-learning/">machine learning</a></div><div class="addthis addthis_toolbox addthis_default_style"><a class="addthis_button_facebook_like" fb:like:layout="button_count"></a> <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a> <a class="addthis_counter addthis_pill_style"></a></div><script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script><div class="clearfix"></div></footer></div></article><section id="comment"><h1 class="title">留言</h1><div id="fb-root"></div><script>!function(e,t,n){var a,c=e.getElementsByTagName(t)[0];e.getElementById(n)||((a=e.createElement(t)).id=n,a.src="//connect.facebook.net/en_US/all.js#xfbml=1&appId=123456789012345",c.parentNode.insertBefore(a,c))}(document,"script","facebook-jssdk")</script><div class="fb-comments" data-href="http://www.wangpengcufe.com/machinelearning/pythonml-pythonml5/index.html" data-num-posts="5" data-width="840" data-colorscheme="light"></div></section></div></div><aside id="sidebar" class="alignright"><script language="javascript">function search(e){return e.method="get",e.action="http://www.baidu.com/baidu",document.search_form.word.value=document.search_form.word.value,!0}</script><div class="search"><form name="search_form" target="_blank" onsubmit="search(this)"><input type="search" name="word" results="0" placeholder="百度站内搜索" onblur='this.value=""'></form></div><div class="widget tag"><h3 class="title">分类</h3><ul class="entry"><li><a href="/categories/read/">read</a><small>69</small></li><li><a href="/categories/tools/">工具</a><small>7</small></li><li><a href="/categories/machinelearning/">机器学习</a><small>25</small></li><li><a href="/categories/navigate/">菜单导航</a><small>1</small></li><li><a href="/categories/datadownload/">资料下载</a><small>1</small></li></ul></div><div class="widget tag"><h3 class="title">标签</h3><ul class="entry"><li><a href="/tags/content/">content</a><small>100</small></li><li><a href="/tags/library/">library</a><small>1</small></li><li><a href="/tags/machine-learning/">machine learning</a><small>25</small></li><li><a href="/tags/navigate/">navigate</a><small>1</small></li><li><a href="/tags/tools/">tools</a><small>7</small></li></ul></div><div class="widget tag"><h3 class="title">友情链接</h3><ul class="entry"><li><a href="http://blog.didispace.com" title="程序员DD">程序员DD</a></li><li><a href="https://mangoroom.cn" title="芒果的个人博客">芒果的个人博客</a></li><li><a href="http://www.baimin.com" target="_blank">百鸣网站百科</a></li><li><a href="http://blog.sina.com.cn/u/2435344920" target="_blank">默默读书</a></li><li><a href="https://www.jianshu.com/u/510007ddad06" target="_blank">王小鹏的随笔（简书）</a></li><li><a href="https://me.csdn.net/weixin_42438712" target="_blank">机器学习（csdn博客）</a></li><li><a href="https://zhuanlan.zhihu.com/c_1182309165824901120" target="_blank">机器学习（知乎）</a></li><li><a href="http://meixiaohan.com/" target="_blank">小寒大人的blog</a></li><li><a href="https://baippt.com/" target="_blank">ppt模板免费下载</a></li><li><a href="http://www.youneedcn.com/" target="_blank">你要的资源</a></li></ul></div></aside><div class="clearfix"></div></div><footer id="footer" class="inner"><div class="alignleft">&copy; 2020 王小鹏 京ICP备19037345号-1</div><div class="clearfix"></div><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></footer><script src="//ajax.useso.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script><script src="/js/jquery.imagesloaded.min.js"></script><script src="/js/gallery.js"></script><link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css"><script src="/fancybox/jquery.fancybox.pack.js"></script><script type="text/javascript">jQuery(".fancybox").fancybox()</script></body></html>