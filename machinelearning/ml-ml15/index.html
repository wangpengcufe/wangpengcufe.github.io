<!DOCTYPE HTML><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta name="baidu-site-verification" content="kZmc8XTvrB"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?458cfc1440d057b6b8799400c6b2e2bf";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><meta charset="utf-8"><title>机器学习（十五） 特征选择-卡方选择器 | 机器学习 and 数据科学</title><meta name="author" content="王小鹏  京ICP备19037345号-1"><meta name="keywords" content="机器学习,卡方选择器,特征选择 PDF电子书下载,电子书，PDF下载"><meta name="description" content="PDF电子书下载,电子书，PDF下载"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta property="og:title" content="机器学习（十五） 特征选择-卡方选择器"><meta property="og:site_name" content="机器学习 and 数据科学"><meta property="og:image" content><link href="/favicon.png" rel="icon"><link rel="alternate" href="/atom.xml" title="机器学习 and 数据科学" type="application/atom+xml"><link rel="stylesheet" href="/css/style.css" media="screen" type="text/css"><!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]--></head><body><header id="header" class="inner"><div class="alignleft"><h1><a href="/">机器学习 and 数据科学</a></h1><h2><a href="/">明天幸福今天修</a></h2></div><nav id="main-nav" class="alignright"><ul><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/about">关于</a></li></ul><div class="clearfix"></div></nav><div class="clearfix"></div></header><div id="content" class="inner"><div id="main-col" class="alignleft"><div id="wrapper"><article id="post-ml-ml15" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting"><div class="post-content"><header><div class="icon"></div><time class="dt-published" datetime="2019-11-20T15:28:56.000Z"><a href="/machinelearning/ml-ml15/">2019-11-20</a><span id="busuanzi_container_page_pv"> &nbsp;&nbsp;&nbsp;&nbsp;阅读 <span id="busuanzi_value_page_pv"></span></span></time><h1 class="p-name title" itemprop="headline name">机器学习（十五） 特征选择-卡方选择器</h1></header><div class="e-content entry" itemprop="articleBody"><p><img src="http://wangpengcufe.com/ml15.png" alt="卡方选择器"></p><a id="more"></a><h1 id="一、公式"><a href="#一、公式" class="headerlink" title="一、公式"></a><strong>一、公式</strong></h1><p>卡方检验的基本公式，也就是χ2的计算公式，即观察值和理论值之间的偏差</p><p><img src="http://wangpengcufe.com/ml15-1.png" alt="卡方检验公式"></p><p>其中：A 为观察值，E为理论值，k为观察值的个数，最后一个式子实际上就是具体计算的方法了 n 为总的频数，p为理论频率，那么n*p自然就是理论频数（理论值）</p><h1 id="二、相关概念"><a href="#二、相关概念" class="headerlink" title="二、相关概念"></a><strong>二、相关概念</strong></h1><p><strong>卡方分布</strong>：可以看出当观察值和理论值十分接近的时候，也就是我们做的假设是正确的时候，χ2的值就越趋近于0，也就是说我们计算的偏差越小，那么假设值就越可能是对的，反之偏差值越大，假设值就越不准确。那么到底多大才算不准确，有没有个衡量的数值标准呢？答案是有：卡方分布。</p><p>卡方检验是以χ2分布为基础的一种常用假设检验方法。若k 个随机变量Z1、……、Zk 相互独立，且数学期望为0、方差为 1(即服从标准正态分布)，则随机变量X被称为服从自由度为 k 的卡方分布，记作</p><p><img src="http://wangpengcufe.com/ml15-2.png" alt="卡方分布"></p><p>，卡方分布的公式为：</p><p><img src="http://wangpengcufe.com/ml15-3.png" alt="卡方分布"></p><p><strong>自由度</strong>：自由度指的是计算某一统计量时，取值不受限制的变量个数。通常df=n-k。其中n为样本数量，k为被限制的条件数或变量个数。自由度v=（行数-1）（列数-1）。</p><p><strong>自由度与卡方分布的关系</strong>：</p><p>如图</p><p><img src="http://wangpengcufe.com/ml15-4.png" alt="自由度与卡方分布的关系图"></p><p>图中的Freedom 这里有5条线，分别对应Freedom=1, 4, 10, 20 , 100 。这个Freedom 就是自由度，即个式子中独立变量的个数。 x 横坐标是卡方检验公式计算出来的偏差χ2，而 y 纵坐标表示假设的正确的概率。当自由度为1时，卡方分布式一个倾斜的曲线，当自由度逐渐增大是，卡方分布逐步变的平缓。在一定范围内，随着自由度越来越大，卡方分布会越来越接近正态分布。</p><h1 id="三、利用卡方检验用来特征选择"><a href="#三、利用卡方检验用来特征选择" class="headerlink" title="三、利用卡方检验用来特征选择"></a><strong>三、利用卡方检验用来特征选择</strong></h1><p><strong>特征选择（Feature Selection）</strong>：指的是在特征向量中选择出那些“优秀”的特征，组成新的、更“精简”的特征向量的过程。它在高维数据分析中十分常用，可以剔除掉“冗余”和“无关”的特征，提升学习器的性能。</p><p>特征选择方法和分类方法一样，也主要分为有监督（Supervised）和无监督（Unsupervised）两种，卡方选择则是统计学上常用的一种有监督特征选择方法，它通过对特征和真实标签之间进行卡方检验，来判断该特征和真实标签的关联程度，进而确定是否对其进行选择。</p><p>对于建立模型而言并非特征越多越好，因为建模的目标是使用尽量简单的模型去实现尽量好的效果。减少一些价值小贡献小的特征有利于在表现效果不变或降低度很小的前提下，新找到最简单的模型。</p><p>那么什么样的特征是价值小的呢？想想我们之所以用机器学习的模型去学习特征，是为了更好地预测被特征影响着的应变量（标签）。那么那些根本不会对应变量产生影响，或者影响很小的特征理应事先去掉。</p><p>那么怎么判断特征对应变量的影响程度的大小呢？我们可以使用卡方检验对特征与应变量进行独立性检验，如果独立性高，那么表示两者没太大关系，特征可以舍弃；如果独立性小，两者相关性高，则说明该特征会对应变量产生比较大的影响，应当选择。</p><p>卡方检验在实际应用到特征选择中的时候，不需要知道自由度，也不用知道卡方分布，只需要根据算出来的χ2 进行排序即可，值越大越好。挑选最大的一堆，就完成了利用卡方检验来进行特征提取。</p><h1 id="四、代码实现"><a href="#四、代码实现" class="headerlink" title="四、代码实现"></a><strong>四、代码实现</strong></h1><p>和ML库中的大多数学习方法一样，ML中的卡方选择也是以estimator+transformer的形式出现的，其主要由ChiSqSelector和ChiSqSelectorModel两个类来实现。</p><p>1、首先引入相关需要用的包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import java.util.Arrays;</span><br><span class="line">import java.util.List;</span><br><span class="line">import org.apache.spark.ml.feature.ChiSqSelector;</span><br><span class="line">import org.apache.spark.ml.feature.ChiSqSelectorModel;</span><br><span class="line">import org.apache.spark.ml.linalg.VectorUDT;</span><br><span class="line">import org.apache.spark.ml.linalg.Vectors;</span><br><span class="line">import org.apache.spark.sql.Dataset;</span><br><span class="line">import org.apache.spark.sql.Row;</span><br><span class="line">import org.apache.spark.sql.RowFactory;</span><br><span class="line">import org.apache.spark.sql.SparkSession;</span><br><span class="line">import org.apache.spark.sql.types.DataTypes;</span><br><span class="line">import org.apache.spark.sql.types.Metadata;</span><br><span class="line">import org.apache.spark.sql.types.StructField;</span><br><span class="line">import org.apache.spark.sql.types.StructType;</span><br></pre></td></tr></table></figure><p>2、接下来获取spark</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SparkSession spark =  SparkSession.builder().appName(&quot;ChiSqSelectorTest&quot;).master(&quot;local&quot;).getOrCreate();</span><br></pre></td></tr></table></figure><p>3、然后，我们构造一个数据集DataFrame：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Row&gt; rawData = Arrays.asList(RowFactory.create(1, Vectors.dense(0.0, 0.0, 18.0, 1.0), 1),</span><br><span class="line">                                  RowFactory.create(2, Vectors.dense(0.0, 1.0, 12.0, 0.0), 0),</span><br><span class="line">                                  RowFactory.create(3, Vectors.dense(1.0, 0.0, 15.0, 0.1), 0));</span><br><span class="line">StructType schema = new StructType(new StructField[] &#123;</span><br><span class="line">        new StructField(&quot;id&quot;,DataTypes.IntegerType,false,Metadata.empty()),    </span><br><span class="line">        new StructField(&quot;features&quot;,new VectorUDT(),false,Metadata.empty()),</span><br><span class="line">        new StructField(&quot;label&quot;,DataTypes.IntegerType,false,Metadata.empty())</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">Dataset&lt;Row&gt; df = spark.createDataFrame(rawData,schema);</span><br><span class="line">df.show(false);</span><br></pre></td></tr></table></figure><p>打印结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+---+------------------+-----+</span><br><span class="line">|id |features          |label|</span><br><span class="line">+---+------------------+-----+</span><br><span class="line">|1  |[0.0,0.0,18.0,1.0]|1    |</span><br><span class="line">|2  |[0.0,1.0,12.0,0.0]|0    |</span><br><span class="line">|3  |[1.0,0.0,15.0,0.1]|0    |</span><br><span class="line">+---+------------------+-----+</span><br></pre></td></tr></table></figure><p>4、接着我们开始用卡方选择进行特征选择器的训练</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ChiSqSelector select = new ChiSqSelector().setNumTopFeatures(1)</span><br><span class="line">                                          .setFeaturesCol(&quot;features&quot;)</span><br><span class="line">                                          .setLabelCol(&quot;label&quot;)</span><br><span class="line">                                          .setOutputCol(&quot;selected-feature&quot;);</span><br><span class="line">ChiSqSelectorModel selectModel = select.fit(df);</span><br><span class="line">Dataset&lt;Row&gt; result = selectModel.transform(df);</span><br><span class="line">result.show(false);</span><br></pre></td></tr></table></figure><p>numTopFeatures：用来设置固定的提取特征的数量，程序会根据卡方值的高低返回前n个卡方值最高的特征。（预测能力最强的前n个特征），默认选择前50个特征。这里，我们设置ChiSqSelector（卡方选择器）的numTopFeatures = 1，即在4个特征中选择处最好的1个特征。</p><p>打印结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+---+------------------+-----+----------------+</span><br><span class="line">|id |features          |label|selected-feature|</span><br><span class="line">+---+------------------+-----+----------------+</span><br><span class="line">|1  |[0.0,0.0,18.0,1.0]|1    |[18.0]          |</span><br><span class="line">|2  |[0.0,1.0,12.0,0.0]|0    |[12.0]          |</span><br><span class="line">|3  |[1.0,0.0,15.0,0.1]|0    |[15.0]          |</span><br><span class="line">+---+------------------+-----+----------------+</span><br></pre></td></tr></table></figure><p>用训练出的模型对原数据集进行处理，可以看见，第三列特征被选出作为最有用的特征列。</p><p><strong>参考资料：</strong> <a href="http://spark.apache.org/docs/latest/ml-features.html#chisqselector" title="http://spark.apache.org/docs/latest/ml-features.html#chisqselector" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/ml-features.html#chisqselector</a></p></div><footer><div class="categories"><a href="/categories/machinelearning/">机器学习</a></div><div class="tags"><a href="/tags/content/">content</a>, <a href="/tags/machine-learning/">machine learning</a></div><div class="addthis addthis_toolbox addthis_default_style"><a class="addthis_button_facebook_like" fb:like:layout="button_count"></a> <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a> <a class="addthis_counter addthis_pill_style"></a></div><script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script><div class="clearfix"></div></footer></div></article><section id="comment"><h1 class="title">留言</h1><div id="fb-root"></div><script>!function(e,t,n){var a,c=e.getElementsByTagName(t)[0];e.getElementById(n)||((a=e.createElement(t)).id=n,a.src="//connect.facebook.net/en_US/all.js#xfbml=1&appId=123456789012345",c.parentNode.insertBefore(a,c))}(document,"script","facebook-jssdk")</script><div class="fb-comments" data-href="http://www.wangpengcufe.com/machinelearning/ml-ml15/index.html" data-num-posts="5" data-width="840" data-colorscheme="light"></div></section></div></div><aside id="sidebar" class="alignright"><script language="javascript">function search(e){return e.method="get",e.action="http://www.baidu.com/baidu",document.search_form.word.value=document.search_form.word.value,!0}</script><div class="search"><form name="search_form" target="_blank" onsubmit="search(this)"><input type="search" name="word" results="0" placeholder="百度站内搜索" onblur='this.value=""'></form></div><div class="widget tag"><h3 class="title">分类</h3><ul class="entry"><li><a href="/categories/read/">read</a><small>63</small></li><li><a href="/categories/tools/">工具</a><small>2</small></li><li><a href="/categories/machinelearning/">机器学习</a><small>16</small></li><li><a href="/categories/navigate/">菜单导航</a><small>1</small></li><li><a href="/categories/datadownload/">资料下载</a><small>1</small></li></ul></div><div class="widget tag"><h3 class="title">标签</h3><ul class="entry"><li><a href="/tags/content/">content</a><small>80</small></li><li><a href="/tags/library/">library</a><small>1</small></li><li><a href="/tags/machine-learning/">machine learning</a><small>16</small></li><li><a href="/tags/navigate/">navigate</a><small>1</small></li><li><a href="/tags/tools/">tools</a><small>2</small></li></ul></div><div class="widget tag"><h3 class="title">友情链接</h3><ul class="entry"><li><a href="http://blog.didispace.com" title="程序员DD">程序员DD</a></li><li><a href="https://mangoroom.cn" title="芒果的个人博客">芒果的个人博客</a></li><li><a href="http://www.baimin.com" target="_blank">百鸣网站百科</a></li><li><a href="http://blog.sina.com.cn/u/2435344920" target="_blank">默默读书</a></li><li><a href="https://www.jianshu.com/u/510007ddad06" target="_blank">王小鹏的随笔</a></li><li><a href="https://me.csdn.net/weixin_42438712" target="_blank">wangpengcufe的csdn博客</a></li><li><a href="http://meixiaohan.com/" target="_blank">小寒大人的blog</a></li></ul></div></aside><div class="clearfix"></div></div><footer id="footer" class="inner"><div class="alignleft">&copy; 2019 王小鹏 京ICP备19037345号-1</div><div class="clearfix"></div><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></footer><script src="//ajax.useso.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script><script src="/js/jquery.imagesloaded.min.js"></script><script src="/js/gallery.js"></script><link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css"><script src="/fancybox/jquery.fancybox.pack.js"></script><script type="text/javascript">jQuery(".fancybox").fancybox()</script></body></html>