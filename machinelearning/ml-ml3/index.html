<!DOCTYPE HTML><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta name="baidu-site-verification" content="kZmc8XTvrB"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?458cfc1440d057b6b8799400c6b2e2bf";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><meta charset="utf-8"><title>机器学习（三）基本的统计工具 | 机器学习 and 数据科学</title><meta name="author" content="王小鹏  京ICP备19037345号-1"><meta name="keywords" content="机器学习,基本的统计工具 PDF电子书下载,电子书，PDF下载"><meta name="description" content="PDF电子书下载,电子书，PDF下载"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta property="og:title" content="机器学习（三）基本的统计工具"><meta property="og:site_name" content="机器学习 and 数据科学"><meta property="og:image" content><link href="/favicon.png" rel="icon"><link rel="alternate" href="/atom.xml" title="机器学习 and 数据科学" type="application/atom+xml"><link rel="stylesheet" href="/css/style.css" media="screen" type="text/css"><!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]--></head><body><header id="header" class="inner"><div class="alignleft"><h1><a href="/">机器学习 and 数据科学</a></h1><h2><a href="/">明天幸福今天修</a></h2></div><nav id="main-nav" class="alignright"><ul><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/about">关于</a></li></ul><div class="clearfix"></div></nav><div class="clearfix"></div></header><div id="content" class="inner"><div id="main-col" class="alignleft"><div id="wrapper"><article id="post-ml-ml3" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting"><div class="post-content"><header><div class="icon"></div><time class="dt-published" datetime="2019-08-30T07:32:39.000Z"><a href="/machinelearning/ml-ml3/">2019-08-30</a><span id="busuanzi_container_page_pv"> &nbsp;&nbsp;&nbsp;&nbsp;阅读 <span id="busuanzi_value_page_pv"></span></span></time><h1 class="p-name title" itemprop="headline name">机器学习（三）基本的统计工具</h1></header><div class="e-content entry" itemprop="articleBody"><p>标签： machine learning</p><p><img src="/machinelearning/ml-ml3/1.png" alt="图1"></p><a id="more"></a><p>给定一个数据集，数据分析师一般会先观察一下数据集的基本情况，称之为汇总统计或者概要性统计。一般的概要性统计用于概括一系列观测值，包括位置或集中趋势（比如算术平均值、中位数、众数和四分位均值），展型（比如四分位间距、绝对偏差和绝对距离偏差、各阶矩等），统计离差，分布的形状，依赖性等。除此之外，spark.mllib库也提供了一些其他的基本的统计分析工具，包括相关性、分层抽样、假设检验，随机数生成等。</p><h1 id="一、概括统计-summary-statistics"><a href="#一、概括统计-summary-statistics" class="headerlink" title="一、概括统计 summary statistics"></a><strong>一、概括统计 summary statistics</strong></h1><p>我们通过统计学中提供的函数colStats为RDD [Vector]提供列摘要统计信息。我们可以获得每一列的最大值，最小值，均值、方差、总数。</p><p>我们用UCI 提供的莺尾花的数据来举例。 数据下载地址：<a href="http://archive.ics.uci.edu/ml/machine-learning-databases/iris/。我们将鸢尾花的四个属性，即萼片长度，萼片宽度，花瓣长度和花瓣宽度存储在observations中，类型为RDD[Vector]。" target="_blank" rel="noopener">http://archive.ics.uci.edu/ml/machine-learning-databases/iris/。我们将鸢尾花的四个属性，即萼片长度，萼片宽度，花瓣长度和花瓣宽度存储在observations中，类型为RDD[Vector]。</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.spark.SparkConf;</span><br><span class="line">import org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line">import org.apache.spark.api.java.JavaRDD;</span><br><span class="line">import org.apache.spark.mllib.linalg.Vector;</span><br><span class="line">import org.apache.spark.mllib.linalg.Vectors;</span><br><span class="line">import  org.apache.spark.mllib.stat.MultivariateStatisticalSummary;</span><br><span class="line">import org.apache.spark.mllib.stat.Statistics; </span><br><span class="line"></span><br><span class="line">SparkConf conf = new  SparkConf().setAppName(&quot;colStatsTest&quot;).setMaster(&quot;local&quot;);</span><br><span class="line">JavaSparkContext  sc = new  JavaSparkContext(conf);</span><br><span class="line">JavaRDD&lt;String&gt; source =  sc.textFile(&quot;data/iris.data&quot;); // 读取数据</span><br><span class="line">JavaRDD&lt;Vector&gt; observations = source.map(line  -&gt; &#123;     </span><br><span class="line">    String[] parts = line.split(&quot;,&quot;);     </span><br><span class="line">    return  Vectors.dense(Double.valueOf(parts[0]),  Double.valueOf(parts[1]),               </span><br><span class="line">    Double.valueOf(parts[2]),  Double.valueOf(parts[3]));//将RDD&lt;String&gt;转化为RDD&lt;Vector&gt;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">MultivariateStatisticalSummary summary =  Statistics.colStats(observations.rdd());   //计算列摘要统计信息。</span><br><span class="line">System.out.println(summary.count()); //总数(long)</span><br><span class="line">System.out.println(summary.mean());  //  包含每列平均值的密集向量(vector)</span><br><span class="line">System.out.println(summary.variance());   // 列方差(vector)</span><br><span class="line">System.out.println(summary.max());   // 最大值(vector)</span><br><span class="line">System.out.println(summary.min());   // 最小值(vector)</span><br><span class="line">System.out.println(summary.normL1());   //每列的L1范数(vector)</span><br><span class="line">System.out.println(summary.normL2());   //每列的L2范数(vector)</span><br><span class="line">System.out.println(summary.numNonzeros());  //  每列中的非零数(vector)</span><br></pre></td></tr></table></figure><h1 id="二、相关性"><a href="#二、相关性" class="headerlink" title="二、相关性"></a><strong>二、相关性</strong></h1><p>计算两个数据系列之间的相关性是统计学中的常见操作。 在spark.mllib中，我们提供了计算多个系列之间成对相关性的灵活性。 支持的相关方法目前是Pearson和Spearman的相关性。</p><p>相关系数是用以反映变量之间相关关系密切程度的统计指标。简单的来说就是相关系数绝对值越大（值越接近1或者-1）,当取值为0表示不相关，取值为(0~-1]表示负相关，取值为(0, 1]表示正相关。</p><h2 id="2-1、Pearson相关系数"><a href="#2-1、Pearson相关系数" class="headerlink" title="2.1、Pearson相关系数"></a><strong>2.1、Pearson相关系数</strong></h2><p>Pearson相关系数表达的是两个数值变量的线性相关性, 它一般适用于正态分布。其取值范围是[-1, 1], 当取值为0表示不相关，取值为[-1~0)表示负相关，取值为(0, 1]表示正相关。</p><p><img src="/machinelearning/ml-ml3/2.png" alt="图2"></p><h1 id="2-2、Spearman相关系数"><a href="#2-2、Spearman相关系数" class="headerlink" title="2.2、Spearman相关系数"></a><strong>2.2、Spearman相关系数</strong></h1><p>Spearman相关系数也用来表达两个变量的相关性，但是它没有Pearson相关系数对变量的分布要求那么严格，另外Spearman相关系数可以更好地用于测度变量的排序关系。其计算公式为：</p><p><img src="/machinelearning/ml-ml3/3.png" alt="图3"></p><p>统计提供了计算序列之间相关性的方法。 根据输入类型，两个JavaDoubleRDD或JavaRDD<vector>，输出将分别为Double或相关矩阵。</vector></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">JavaDoubleRDD seriesX =  source.mapToDouble(x-&gt;Double.parseDouble(x.split(&quot;,&quot;)[0]));</span><br><span class="line">JavaDoubleRDD seriesY =  source.mapToDouble(x-&gt;Double.parseDouble(x.split(&quot;,&quot;)[1]));  //必须具有与seriesX相同数量的分区和基数</span><br><span class="line">Double correlation =  Statistics.corr(seriesX.srdd(), seriesY.srdd(),  &quot;pearson&quot;);//使用Pearson方法计算相关性。 为Spearman的方法输入“spearman”。</span><br><span class="line">//如果未指定方法，默认情况下将使用Pearson的方法。</span><br><span class="line"></span><br><span class="line">System.out.println(&quot;Correlation is: &quot; +  correlation);</span><br><span class="line"></span><br><span class="line">/**控制台输出结果：</span><br><span class="line">-------------------------------------</span><br><span class="line">Correlation is: -0.10936924995062468</span><br><span class="line">-------------------------------------</span><br><span class="line">**/</span><br></pre></td></tr></table></figure><p>说明数据集的前两列，即花萼长度和花萼宽度具有微小的负相关性。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Vector&gt; data = source.map(line -&gt; &#123;     </span><br><span class="line">	String[] parts = line.split(&quot;,&quot;);     </span><br><span class="line">	return  Vectors.dense(Double.valueOf(parts[0]),             </span><br><span class="line">	Double.valueOf(parts[1]));//将RDD&lt;String&gt;转化为RDD&lt;Vector&gt;</span><br><span class="line">&#125;); //请注意，每个Vector都是一行而不是一列</span><br><span class="line">Matrix correlMatrix =  Statistics.corr(data.rdd(), &quot;pearson&quot;);</span><br><span class="line">System.out.println(correlMatrix.toString());</span><br><span class="line"></span><br><span class="line">/**控制台输出结果：</span><br><span class="line"></span><br><span class="line">-------------------------------------------------</span><br><span class="line"></span><br><span class="line">**1.0                   -0.10936924995062468</span><br><span class="line"></span><br><span class="line">**-0.10936924995062468  1.0</span><br><span class="line"></span><br><span class="line">------------------------------------------------</span><br><span class="line"></span><br><span class="line">**/</span><br></pre></td></tr></table></figure><h1 id="三、分层抽样-Stratified-sampling"><a href="#三、分层抽样-Stratified-sampling" class="headerlink" title="三、分层抽样 Stratified sampling"></a><strong>三、分层抽样 Stratified sampling</strong></h1><p>与spark.mllib中的其他统计函数不同，可以对RDD的键值对执行分层抽样方法sampleByKey和sampleByKeyExact。 对于分层抽样，可以将键视为标签，将值视为特定属性。 例如，密钥可以是人或女人，或文档ID，并且相应的值可以是人口中的人的年龄列表或文档中的单词列表。 sampleByKey方法将翻转硬币以决定是否对样本进行采样，因此需要对数据进行一次传递，并提供预期的样本大小。 sampleByKeyExact比sampleByKey中使用的每层简单随机抽样需要更多的资源，但是会提供99.99％置信度的精确抽样大小。</p><h2 id="3-1、sampleByKey-方法"><a href="#3-1、sampleByKey-方法" class="headerlink" title="3.1、sampleByKey 方法"></a><strong>3.1、sampleByKey 方法</strong></h2><p>sampleByKeyExact（）允许用户准确地采样⌈fk⋅nk⌉∀k∈K项，其中fk是密钥k的期望分数，nk是密钥k的键 - 值对的数量，K是密钥集。 无需更换的采样需要在RDD上额外通过一次以确保样本大小，而更换采样则需要两次额外的通过。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.spark.SparkConf;</span><br><span class="line">import org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line">import org.apache.spark.api.java.JavaRDD;</span><br><span class="line">import org.apache.spark.api.java.JavaPairRDD;</span><br><span class="line">import org.spark_project.guava.collect.ImmutableMap;</span><br><span class="line">import scala.Tuple2;</span><br><span class="line"></span><br><span class="line">List&lt;Tuple2&lt;String, String&gt;&gt; list =  Arrays.asList(                </span><br><span class="line">		new Tuple2&lt;&gt;(&quot;female&quot;,&quot;Lily&quot;),                </span><br><span class="line">		new Tuple2&lt;&gt;(&quot;female&quot;,&quot;Lucy&quot;),                </span><br><span class="line">		new Tuple2&lt;&gt;(&quot;female&quot;,&quot;Emily&quot;),               </span><br><span class="line">	 	new Tuple2&lt;&gt;(&quot;female&quot;,&quot;Kate&quot;),               </span><br><span class="line">	 	new Tuple2&lt;&gt;(&quot;female&quot;,&quot;Alice&quot;),                </span><br><span class="line">		new Tuple2&lt;&gt;(&quot;male&quot;,&quot;Tom&quot;),               </span><br><span class="line">	 	new Tuple2&lt;&gt;(&quot;male&quot;,&quot;Roy&quot;),                </span><br><span class="line">		new Tuple2&lt;&gt;(&quot;male&quot;,&quot;David&quot;),                </span><br><span class="line">		new Tuple2&lt;&gt;(&quot;male&quot;,&quot;Frank&quot;),                </span><br><span class="line">		new Tuple2&lt;&gt;(&quot;male&quot;,&quot;Jack&quot;));//创建了一组数据，分成 “female” 和  “male” 两类 </span><br><span class="line"></span><br><span class="line">JavaPairRDD&lt;String, String&gt; data =  sc.parallelizePairs(list);</span><br><span class="line">ImmutableMap&lt;String, Double&gt; fractions =  new ImmutableMap.Builder&lt;String,Double&gt;()               </span><br><span class="line">					 	.put(&quot;female&quot;,0.6)                </span><br><span class="line">						.put(&quot;male&quot;,0.4)                </span><br><span class="line">						.build();  //从每个键Map &lt;K，Double&gt;中指定所需的精确分数</span><br></pre></td></tr></table></figure><p>这里，设置采取60%的female和40%的male，因为数据中female和male各有5个样本，所以理想中的抽样结果应该是有3个female和2个male。接下来用sampleByKey进行抽样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">JavaPairRDD&lt;String, String&gt; approxSample =  data.sampleByKey(false, fractions,1);  //从每个层获取大致样本</span><br><span class="line">approxSample.foreach(x-&gt;&#123;   </span><br><span class="line">	System.out.println(x);   //打印approxSample分层取样的结果;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">/** *控制台输出结果：</span><br><span class="line">------------------</span><br><span class="line">	(female,Lily) </span><br><span class="line">(female,Lucy)</span><br><span class="line">(female,Emily) </span><br><span class="line">(female,Kate) </span><br><span class="line">(male,Roy) </span><br><span class="line">(male,Frank)</span><br><span class="line">------------------</span><br><span class="line">**/</span><br></pre></td></tr></table></figure><p>从上面可以看到，本应该抽取3个female和2个male，但结果抽取了5个female和1个male，结果并不够准确，不过在样本数量足够大且要求一定效率的情况下，用sampleByKey进行抽样还是可行的。</p><h2 id="3-2、sampleByKeyExact-方法"><a href="#3-2、sampleByKeyExact-方法" class="headerlink" title="3.2、sampleByKeyExact 方法"></a><strong>3.2、sampleByKeyExact 方法</strong></h2><p>sampleByKey 和 sampleByKeyExact 的区别在于 sampleByKey 每次都通过给定的概率以一种类似于掷硬币的方式来决定这个观察值是否被放入样本，因此一遍就可以过滤完所有数据，最后得到一个近似大小的样本，但往往不够准确。而 sampleByKeyExtra 会对全量数据做采样计算。对于每个类别，其都会产生 （fk⋅nk）个样本，其中fk是键为k的样本类别采样的比例；nk是键k所拥有的样本数。 sampleByKeyExtra 采样的结果会更准确，有99.99%的置信度，但耗费的计算资源也更多。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">JavaPairRDD&lt;String, String&gt; exactSample =  data.sampleByKeyExact(false, fractions,1);</span><br><span class="line">exactSample.foreach(x-&gt;&#123;     </span><br><span class="line">System.out.println(x);//打印exactSample分层取样的结果;&#125;);</span><br><span class="line"></span><br><span class="line">/***控制台输出结果：</span><br><span class="line">-------------------</span><br><span class="line">(female,Lily)</span><br><span class="line">(female,Emily)</span><br><span class="line">(female,Kate)</span><br><span class="line">(male,Roy)</span><br><span class="line">(male,Frank)</span><br><span class="line">--------------------</span><br><span class="line">**/</span><br></pre></td></tr></table></figure><p>从实验结果可以看出，所得结果和预想一致，但当样本数量比较大时，可能会耗时较久。</p><h1 id="四、假设检验-hypothesis-testing"><a href="#四、假设检验-hypothesis-testing" class="headerlink" title="四、假设检验 hypothesis testing"></a><strong>四、假设检验 hypothesis testing</strong></h1><p>假设检验是统计学中一种强有力的工具，用于确定结果是否具有统计显着性，无论该结果是否偶然发生。 spark.mllib目前支持Pearson的卡方（χ2）测试，以确保拟合和独立性。 不同的输入类型决定了是做拟合度检验还是独立性检验。拟合度检验要求输入为Vector, 独立性检验要求输入是Matrix。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.spark.SparkConf;</span><br><span class="line">import org.apache.spark.api.java.JavaRDD;	</span><br><span class="line">import org.apache.spark.api.java.JavaSparkContext;	</span><br><span class="line">import org.apache.spark.mllib.linalg.Matrices;	</span><br><span class="line">import org.apache.spark.mllib.linalg.Matrix;	</span><br><span class="line">import org.apache.spark.mllib.linalg.Vector;	</span><br><span class="line">import org.apache.spark.mllib.linalg.Vectors;	</span><br><span class="line">import org.apache.spark.mllib.stat.Statistics;	</span><br><span class="line">import org.apache.spark.mllib.stat.test.ChiSqTestResult;	</span><br><span class="line"></span><br><span class="line">JavaRDD&lt;Vector&gt; vectors1 = source.map(x-&gt;&#123;     	</span><br><span class="line">String[] splits = x.split(&quot;,&quot;);    	</span><br><span class="line">return  Vectors.dense(Double.parseDouble(splits[0]),             	</span><br><span class="line">			 Double.parseDouble(splits[1]),               	</span><br><span class="line">			 Double.parseDouble(splits[2]),               	</span><br><span class="line">			 Double.parseDouble(splits[3]));	</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">Vector v1 = vectors1.first();//获取  iris数据集中的第1条记录 ，类型为Vector</span><br><span class="line">Vector v2 = vectors1.take(2).get(1);//获取 iris数据集中的第2条记录 ，类型为Vector</span><br></pre></td></tr></table></figure><h2 id="4-1、适合度检验-Goodness-fo-fit"><a href="#4-1、适合度检验-Goodness-fo-fit" class="headerlink" title="4.1、适合度检验 Goodness fo fit"></a><strong>4.1、适合度检验 Goodness fo fit</strong></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">ChiSqTestResult goodnessOfFitTestResult =  Statistics.chiSqTest(v1);	</span><br><span class="line">System.out.println(&quot;goodnessOfFitTestResult:&quot;+goodnessOfFitTestResult);	</span><br><span class="line"></span><br><span class="line">/***控制台输出结果：	</span><br><span class="line">--------------------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">goodnessOfFitTestResult:Chi squared test summary:	</span><br><span class="line">method: pearson	</span><br><span class="line">degrees of freedom = 3</span><br><span class="line">statistic = 5.588235294117647</span><br><span class="line">pValue = 0.1334553914430291</span><br><span class="line">No presumption against null hypothesis: observed follows the same distribution as  expected..</span><br><span class="line">----------------------------------------------------------------------------------------------</span><br></pre></td></tr></table></figure><p>**/<br>可以看到P值，自由度，检验统计量，所使用的方法，以及零假设等信息。我们先简单介绍下每个输出的意义：</p><p>method: 方法。这里采用pearson方法。</p><p>statistic： 检验统计量。简单来说就是用来决定是否可以拒绝原假设的证据。检验统计量的值是利用样本数据计算得到的，它代表了样本中的信息。检验统计量的绝对值越大，拒绝原假设的理由越充分，反之，不拒绝原假设的理由越充分。</p><p>degrees of freedom：自由度。表示可自由变动的样本观测值的数目，</p><p>pValue：统计学根据显著性检验方法所得到的P 值。一般以P &lt; 0.05 为显著， P&lt;0.01 为非常显著，其含义是样本间的差异由抽样误差所致的概率小于0.05 或0.01。</p><p>一般来说，假设检验主要看P值就够了。在本例中pValue =0.133，说明两组的差别无显著意义。通过V1的观测值[5.1, 3.5, 1.4, 0.2]，无法拒绝其服从于期望分配（这里默认是均匀分配）的假设。</p><h2 id="4-2、独立性检验-Indenpendence"><a href="#4-2、独立性检验-Indenpendence" class="headerlink" title="4.2、独立性检验 Indenpendence"></a><strong>4.2、独立性检验 Indenpendence</strong></h2><p>卡方独立性检验是用来检验两个属性间是否独立。其中一个属性做为行，另外一个做为列，通过貌似相关的关系考察其是否真实存在相关性。比如天气温变化和肺炎发病率。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Matrix mat = Matrices.dense(2, 2, new  double[]&#123;v1.apply(0), v1.apply(1),v2.apply(0),  v2.apply(1)&#125;);	</span><br><span class="line">System.out.println(&quot;mat:&quot;+mat);	</span><br><span class="line">/***</span><br><span class="line"></span><br><span class="line">控制台输出结果：	</span><br><span class="line">---------------------------</span><br><span class="line"></span><br><span class="line">mat:5.1  4.9  3.5  3.0 </span><br><span class="line"></span><br><span class="line">----------------------------	</span><br><span class="line">**/</span><br></pre></td></tr></table></figure><p>同样的，键值对也可以进行独立性检验，这里我们取iris的数据组成键值对：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;LabeledPoint&gt; LabeledPoints =  source.map(x-&gt;&#123;     	</span><br><span class="line">String[] splits = x.split(&quot;,&quot;);     	</span><br><span class="line">Double label = 0.0;     	</span><br><span class="line">if(splits[4].equals(&quot;Iris-setosa&quot;))  &#123;           	</span><br><span class="line">          label = 0.0;     	</span><br><span class="line">&#125;else  if(splits[4].equals(&quot;Iris-versicolor&quot;)) &#123; 	</span><br><span class="line">          label = 1.0;     	</span><br><span class="line">&#125;else &#123;           </span><br><span class="line">	      label = 2.0;     	</span><br><span class="line">&#125;     	</span><br><span class="line">return  new  LabeledPoint(label,Vectors.dense(Double.parseDouble(splits[0]),                 </span><br><span class="line">     Double.parseDouble(splits[1]),                   	</span><br><span class="line">     Double.parseDouble(splits[2]),               	</span><br><span class="line">     Double.parseDouble(splits[3])));	</span><br><span class="line">&#125;);</span><br><span class="line">ChiSqTestResult[] c2 =  Statistics.chiSqTest(LabeledPoints);	</span><br><span class="line">for (ChiSqTestResult chiSqTestResult :  c2) &#123;   	</span><br><span class="line">    System.out.println(&quot;c2:&quot;+chiSqTestResult);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/***控制台输出结果：</span><br><span class="line">-----------------------------------------------------------------------------------------------------------------</span><br><span class="line">c2:Chi squared test summary:</span><br><span class="line">method: pearson</span><br><span class="line">degrees of freedom = 68</span><br><span class="line">statistic = 156.26666666666665</span><br><span class="line">pValue = 6.6659873176888595E-9</span><br><span class="line">Very strong presumption against null hypothesis: the occurrence of the outcomes is  statistically independent..</span><br><span class="line">c2:Chi squared test summary:</span><br><span class="line">method: pearson</span><br><span class="line">degrees of freedom = 44</span><br><span class="line">statistic = 88.36446886446883</span><br><span class="line">pValue = 8.303947787857702E-5</span><br><span class="line">Very strong presumption against null hypothesis: the occurrence of the outcomes is  statistically independent..</span><br><span class="line">c2:Chi squared test summary:</span><br><span class="line">method: pearson</span><br><span class="line">degrees of freedom = 84</span><br><span class="line">statistic = 271.79999999999995</span><br><span class="line">pValue = 0.0</span><br><span class="line">Very strong presumption against null hypothesis: the occurrence of the outcomes is  statistically independent..</span><br><span class="line">c2:Chi squared test summary:</span><br><span class="line">method: pearson</span><br><span class="line">degrees of freedom = 42statistic = 271.75</span><br><span class="line">pValue = 0.0</span><br><span class="line">Very strong presumption against null hypothesis: the occurrence of the outcomes is  statistically independent..</span><br><span class="line">-----------------------------------------------------------------------------------------------------------------</span><br><span class="line">**/</span><br></pre></td></tr></table></figure><p>这里实际上是把特征数据中的每一列都与标签进行独立性检验。可以看出，P值都非常小，说明可以拒绝“某列与标签列无关”的假设。也就是说，可以认为每一列的数据都与最后的标签有相关性。</p><h1 id="五、随机数生成-random-data-generation"><a href="#五、随机数生成-random-data-generation" class="headerlink" title="五、随机数生成 random data generation"></a><strong>五、随机数生成 random data generation</strong></h1><p>RandomRDDs 是一个工具集，用来生成含有随机数的RDD，可以按各种给定的分布模式生成数据集，Random RDDs包下现支持正态分布、泊松分布和均匀分布三种分布方式。RandomRDDs提供随机double RDDS或vector RDDS。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.spark.SparkConf;	</span><br><span class="line">import org.apache.spark.api.java.JavaDoubleRDD;	</span><br><span class="line">import org.apache.spark.api.java.JavaRDD;	</span><br><span class="line">import  org.apache.spark.api.java.JavaSparkContext;	</span><br><span class="line">import org.apache.spark.mllib.random.RandomRDDs;	</span><br><span class="line">JavaDoubleRDD u = RandomRDDs.normalJavaRDD(sc,  1000000L, 10);  //生成1000000个服从正态分配N(0,1)的RDD[Double]，并且分布在 10 个分区中：	</span><br><span class="line">JavaDoubleRDD v = u.mapToDouble(x-&gt;1.0+2.0*x);    //把生成的随机数转化成N(1,4) 正态分布：</span><br></pre></td></tr></table></figure><h1 id="六、核密度估计-Kernel-density-estimation"><a href="#六、核密度估计-Kernel-density-estimation" class="headerlink" title="六、核密度估计 Kernel density estimation"></a><strong>六、核密度估计 Kernel density estimation</strong></h1><p>Spark ML 提供了一个工具类 KernelDensity 用于核密度估算，核密度估算的意思是根据已知的样本估计未知的密度，属於非参数检验方法之一。核密度估计的原理是。观察某一事物的已知分布，如果某一个数在观察中出现了，可认为这个数的概率密度很大，和这个数比较近的数的概率密度也会比较大，而那些离这个数远的数的概率密度会比较小。Spark1.6.2版本支持高斯核(Gaussian kernel)。</p><pre><code>import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaRDD;
import  org.apache.spark.api.java.JavaSparkContext;
import  org.apache.spark.mllib.stat.KernelDensity;

JavaRDD&lt;Double&gt; d = source.map(t -&gt;  Double.parseDouble(t.split(&quot;,&quot;)[0]));   //用样本数据构建核函数，这里用假设检验中得到的iris的第一个属性的数据作为样本数据进行估计：
KernelDensity kd = new  KernelDensity().setBandwidth(3.0).setSample(d);  //其中setBandwidth表示高斯核的宽度，为一个平滑参数，可以看做是高斯核的标准差。
double[] densities = kd.estimate(new double[]  {-1.0, 2.0, 5.0, 5.8});
System.out.println(Arrays.toString(densities));
/***
控制台输出结果：
------------------------------------------------------------------------------------------
[0.011372003554433527, 0.05992591135719891, 0.12365409462424529,  0.12816280708978112]
------------------------------------------------------------------------------------------
**/ 
</code></pre><p><strong>参考资料：</strong></p><ul><li><p>1、<a href="http://spark.apache.org/docs/latest/mllib-statistics.html" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/mllib-statistics.html</a></p></li><li><p>2、<a href="https://baike.baidu.com/item/spearman%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0/7977847?fr=aladdin" target="_blank" rel="noopener">https://baike.baidu.com/item/spearman%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0/7977847?fr=aladdin</a></p></li><li><p>3、<a href="https://baike.baidu.com/item/%E7%9A%AE%E5%B0%94%E6%A3%AE%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0/4222137?fr=aladdin" target="_blank" rel="noopener">https://baike.baidu.com/item/%E7%9A%AE%E5%B0%94%E6%A3%AE%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0/4222137?fr=aladdin</a></p></li></ul></div><footer><div class="categories"><a href="/categories/machinelearning/">机器学习</a></div><div class="tags"><a href="/tags/content/">content</a>, <a href="/tags/machine-learning/">machine learning</a></div><div class="addthis addthis_toolbox addthis_default_style"><a class="addthis_button_facebook_like" fb:like:layout="button_count"></a> <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a> <a class="addthis_counter addthis_pill_style"></a></div><script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script><div class="clearfix"></div></footer></div></article><section id="comment"><h1 class="title">留言</h1><div id="fb-root"></div><script>!function(e,t,n){var a,c=e.getElementsByTagName(t)[0];e.getElementById(n)||((a=e.createElement(t)).id=n,a.src="//connect.facebook.net/en_US/all.js#xfbml=1&appId=123456789012345",c.parentNode.insertBefore(a,c))}(document,"script","facebook-jssdk")</script><div class="fb-comments" data-href="http://www.wangpengcufe.com/machinelearning/ml-ml3/index.html" data-num-posts="5" data-width="840" data-colorscheme="light"></div></section></div></div><aside id="sidebar" class="alignright"><script language="javascript">function search(e){return e.method="get",e.action="http://www.baidu.com/baidu",document.search_form.word.value=document.search_form.word.value,!0}</script><div class="search"><form name="search_form" target="_blank" onsubmit="search(this)"><input type="search" name="word" results="0" placeholder="百度站内搜索" onblur='this.value=""'></form></div><div class="widget tag"><h3 class="title">分类</h3><ul class="entry"><li><a href="/categories/read/">read</a><small>68</small></li><li><a href="/categories/tools/">工具</a><small>2</small></li><li><a href="/categories/machinelearning/">机器学习</a><small>22</small></li><li><a href="/categories/navigate/">菜单导航</a><small>1</small></li><li><a href="/categories/datadownload/">资料下载</a><small>1</small></li></ul></div><div class="widget tag"><h3 class="title">标签</h3><ul class="entry"><li><a href="/tags/content/">content</a><small>91</small></li><li><a href="/tags/library/">library</a><small>1</small></li><li><a href="/tags/machine-learning/">machine learning</a><small>22</small></li><li><a href="/tags/navigate/">navigate</a><small>1</small></li><li><a href="/tags/tools/">tools</a><small>2</small></li></ul></div><div class="widget tag"><h3 class="title">友情链接</h3><ul class="entry"><li><a href="http://blog.didispace.com" title="程序员DD">程序员DD</a></li><li><a href="https://mangoroom.cn" title="芒果的个人博客">芒果的个人博客</a></li><li><a href="http://www.baimin.com" target="_blank">百鸣网站百科</a></li><li><a href="http://blog.sina.com.cn/u/2435344920" target="_blank">默默读书</a></li><li><a href="https://www.jianshu.com/u/510007ddad06" target="_blank">王小鹏的随笔（简书）</a></li><li><a href="https://me.csdn.net/weixin_42438712" target="_blank">机器学习（csdn博客）</a></li><li><a href="https://zhuanlan.zhihu.com/c_1182309165824901120" target="_blank">机器学习（知乎）</a></li><li><a href="http://meixiaohan.com/" target="_blank">小寒大人的blog</a></li><li><a href="https://baippt.com/" target="_blank">ppt模板免费下载</a></li><li><a href="http://www.youneedcn.com/" target="_blank">你要的资源</a></li></ul></div></aside><div class="clearfix"></div></div><footer id="footer" class="inner"><div class="alignleft">&copy; 2020 王小鹏 京ICP备19037345号-1</div><div class="clearfix"></div><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></footer><script src="//ajax.useso.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script><script src="/js/jquery.imagesloaded.min.js"></script><script src="/js/gallery.js"></script><link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css"><script src="/fancybox/jquery.fancybox.pack.js"></script><script type="text/javascript">jQuery(".fancybox").fancybox()</script></body></html>