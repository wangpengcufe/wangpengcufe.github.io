<!DOCTYPE HTML><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta name="baidu-site-verification" content="kZmc8XTvrB"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?458cfc1440d057b6b8799400c6b2e2bf";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><meta charset="utf-8"><title>机器学习（七） 奇异值分解-SVD | 机器学习 and 数据科学</title><meta name="author" content="王小鹏  京ICP备19037345号-1"><meta name="description" content="机器学习 王鹏 数据科学"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta property="og:title" content="机器学习（七） 奇异值分解-SVD"><meta property="og:site_name" content="机器学习 and 数据科学"><meta property="og:image" content><link href="/favicon.png" rel="icon"><link rel="alternate" href="/atom.xml" title="机器学习 and 数据科学" type="application/atom+xml"><link rel="stylesheet" href="/css/style.css" media="screen" type="text/css"><!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]--></head><body><header id="header" class="inner"><div class="alignleft"><h1><a href="/">机器学习 and 数据科学</a></h1><h2><a href="/">明天幸福今天修</a></h2></div><nav id="main-nav" class="alignright"><ul><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/about">关于</a></li></ul><div class="clearfix"></div></nav><div class="clearfix"></div></header><div id="content" class="inner"><div id="main-col" class="alignleft"><div id="wrapper"><article id="post-ml-ml7" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting"><div class="post-content"><header><div class="icon"></div><time class="dt-published" datetime="2019-09-03T10:42:05.000Z"><a href="/machinelearning/ml-ml7/">2019-09-03</a><span id="busuanzi_container_page_pv"> &nbsp;&nbsp;&nbsp;&nbsp;阅读 <span id="busuanzi_value_page_pv"></span></span></time><h1 class="p-name title" itemprop="headline name">机器学习（七） 奇异值分解-SVD</h1></header><div class="e-content entry" itemprop="articleBody"><p>标签： machine learning</p><p><img src="/machinelearning/ml-ml7/1.png" alt="目录"></p><a id="more"></a><p><strong>降维</strong>（Dimensionality Reduction） 是机器学习中的一种重要的特征处理手段，它可以减少计算过程中考虑到的随机变量（即特征）的个数，其被广泛应用于各种机器学习问题中，用于消除噪声、对抗数据稀疏问题。它在尽可能维持原始数据的内在结构的前提下，得到一组描述原数据的，低维度的隐式特征（或称主要特征）。简单来说，在高维数据中筛选出对我们有用的变量，减小计算复杂度提高模型训练效率和准确率，这就是我们要说的降维。</p><p>MLlib机器学习库提供了两个常用的降维方法：<strong>奇异值分解（Singular Value Decomposition，SVD）</strong> 和 <strong>主成分分析（Principal Component Analysis，PCA）</strong>，下面我们将通过实例介绍其具体的使用方法。</p><h1 id="一、公式和原理"><a href="#一、公式和原理" class="headerlink" title="一、公式和原理"></a><strong>一、公式和原理</strong></h1><p>奇异值分解（SVD）将矩阵A分解为三个矩阵：U，Σ和V，如下公式</p><p><strong>公式</strong>：<img src="/machinelearning/ml-ml7/2.png" alt="图2"></p><p>其中</p><p><strong>左奇异矩阵</strong> :，<strong>U</strong> 为一个标准正交矩阵，也叫实对称矩阵，怎么理解这个概念呢？就是说矩阵A的转置等于其本身，或者说矩阵U的维度为m×m ，用符号表示为<img src="/machinelearning/ml-ml7/3.png" alt="图3">，我们称U 为<strong>左奇异矩阵</strong>。</p><p><strong>奇异值</strong> : <strong>Σ</strong> 是一个对角矩阵，仅在主对角线上有值，其它元素均为0，用符合表示为<img src="/machinelearning/ml-ml7/4.png" alt="图4">，我们称Σ为<strong>奇异值</strong>。</p><p><strong>右奇异矩阵</strong> ： <strong>V</strong>也是一个正交矩阵，这会儿知道是啥意思了吧，和<strong>U</strong>的解释一样，用符号表示为<img src="/machinelearning/ml-ml7/5.png" alt="图5"> ，我们称 <strong>V</strong> 为 <strong>右奇异矩阵</strong>。</p><p><strong>奇异值分解</strong> ： 就是想要找到一个比较小的值k，保留前k个奇异向量和奇异值，其中 <strong>U</strong> 的维度从 m×m 变成了 m×k , <strong>V</strong> 的维度从 n×n 变成了 m×k ，<strong>Σ</strong> 的维度从 m×n 变成了 k×k 的方阵，从而达到降维效果。</p><h1 id="二、代码实现"><a href="#二、代码实现" class="headerlink" title="二、代码实现"></a><strong>二、代码实现</strong></h1><p>Mllib内置的奇异值分解功能位于org.apache.spark.mllib.linalg包下的RowMatrix和IndexedRowMatrix类中，所以，我们必须先通过已有数据创建出相应矩阵类型的对象，然后调用该类的成员方法来进行SVD分解，这里以RowMatrix为例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.spark.SparkConf;</span><br><span class="line">import org.apache.spark.api.java.JavaRDD;</span><br><span class="line">import org.apache.spark.api.java.JavaSparkContext;</span><br><span class="line">import org.apache.spark.mllib.linalg.Matrix;</span><br><span class="line">import org.apache.spark.mllib.linalg.SingularValueDecomposition;</span><br><span class="line">import org.apache.spark.mllib.linalg.Vector;</span><br><span class="line">import org.apache.spark.mllib.linalg.Vectors;</span><br><span class="line">import org.apache.spark.mllib.linalg.distributed.RowMatrix;</span><br></pre></td></tr></table></figure><h2 id="3-1、准备一个矩阵"><a href="#3-1、准备一个矩阵" class="headerlink" title="3.1、准备一个矩阵"></a><strong>3.1、准备一个矩阵</strong></h2><p>准备好一个矩阵，这里我们采用一个简单的文件a.mat来存储一个尺寸为(4,9)的矩阵，其内容如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1 2 3 4 5 6 7 8 9 </span><br><span class="line">5 6 7 8 9 0 8 6 7 </span><br><span class="line">9 0 8 7 1 4 3 2 1 </span><br><span class="line">6 4 2 1 3 4 2 1 5</span><br></pre></td></tr></table></figure><h2 id="3-2、computeSVD方法计算分解结果"><a href="#3-2、computeSVD方法计算分解结果" class="headerlink" title="3.2、computeSVD方法计算分解结果"></a><strong>3.2、computeSVD方法计算分解结果</strong></h2><p>随后，将该文本文件读入成RDD[Vector]，并转换成RowMatrix，即可调用RowMatrix自带的computeSVD方法计算分解结果，这一结果保存在类型为SingularValueDecomposition的svd对象中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">SparkConf conf = new SparkConf().setAppName(&quot;SVD&quot;).setMaster(&quot;local&quot;);</span><br><span class="line">JavaSparkContext sc = new JavaSparkContext(conf);</span><br><span class="line">        </span><br><span class="line">JavaRDD&lt;String&gt; source = sc.textFile(&quot;data/mllib/a.data&quot;);</span><br><span class="line">JavaRDD&lt;Vector&gt; data = source.map(line-&gt;&#123;</span><br><span class="line">    String[] parts = line.split(&quot; &quot;);</span><br><span class="line">    return  Vectors.dense(Double.parseDouble(parts[0]),</span><br><span class="line">            Double.parseDouble(parts[1]),</span><br><span class="line">            Double.parseDouble(parts[2]));</span><br><span class="line">&#125;);</span><br><span class="line">RowMatrix rm = new RowMatrix(data.rdd());</span><br></pre></td></tr></table></figure><h2 id="3-3、保留前3个奇异值"><a href="#3-3、保留前3个奇异值" class="headerlink" title="3.3、保留前3个奇异值"></a><strong>3.3、保留前3个奇异值</strong></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SingularValueDecomposition&lt;RowMatrix,Matrix&gt; svd = rm.computeSVD(3,false,1.0E-9d);</span><br></pre></td></tr></table></figure><h2 id="3-4、得到V、s、U成员"><a href="#3-4、得到V、s、U成员" class="headerlink" title="3.4、得到V、s、U成员"></a><strong>3.4、得到V、s、U成员</strong></h2><p>通过访问svd对象的V、s、U成员分别拿到进行SVD分解后的右奇异矩阵、奇异值向量和左奇异矩阵：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">System.out.println(&quot;s=================&quot;);</span><br><span class="line">System.out.println(svd.s());</span><br><span class="line">System.out.println(&quot;s=================&quot;);</span><br><span class="line"></span><br><span class="line">System.out.println(&quot;V=================&quot;);</span><br><span class="line">System.out.println(svd.V());</span><br><span class="line">System.out.println(&quot;V=================&quot;);</span><br><span class="line"></span><br><span class="line">System.out.println(&quot;U=================&quot;);</span><br><span class="line">System.out.println(svd.U());</span><br><span class="line">System.out.println(&quot;U=================&quot;);</span><br></pre></td></tr></table></figure><p>控制台输出结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">s========================================================</span><br><span class="line">[28.741265581939565,10.847941223452608,7.089519467626695]</span><br><span class="line">s========================================================</span><br><span class="line"></span><br><span class="line">V===============================================================</span><br><span class="line">-0.32908987300830383  0.6309429972945555    0.16077051991193514   </span><br><span class="line">-0.2208243332000108   -0.1315794105679425   -0.2368641953308101   </span><br><span class="line">-0.35540818799208057  0.39958899365222394   -0.147099615168733    </span><br><span class="line">-0.37221718676772064  0.2541945113699779    -0.25918656625268804  </span><br><span class="line">-0.3499773046239524   -0.24670052066546988  -0.34607608172732196  </span><br><span class="line">-0.21080978995485605  0.036424486072344636  0.7867152486535043    </span><br><span class="line">-0.38111806017302313  -0.1925222521055529   -0.09403561250768909  </span><br><span class="line">-0.32751631238613577  -0.3056795887065441   0.09922623079118417   </span><br><span class="line">-0.3982876638452927   -0.40941282445850646  0.26805622896042314 </span><br><span class="line">V===============================================================</span><br><span class="line">  </span><br><span class="line">U====</span><br><span class="line">null</span><br><span class="line">U====</span><br></pre></td></tr></table></figure><p>这里可以看到，由于限定了取前三个奇异值，所以奇异值向量s包含有三个从大到小排列的奇异值，而右奇异矩阵V中的每一列都代表了对应的右奇异向量。 U成员得到的是一个null值，这是因为在实际运用中，只需要V和S两个成员，即可通过矩阵计算达到降维的效果。</p><p>如果需要获得U成员，可以在进行SVD分解时，指定computeU参数，令其等于True，即可在分解后的svd对象中拿到U成员，如下文所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SingularValueDecomposition&lt;RowMatrix,  Matrix&gt; svd = rm.computeSVD(3,true,1.0E-9d);</span><br><span class="line">System.out.println(&quot;U=================&quot;);</span><br><span class="line">System.out.println(svd.U());</span><br><span class="line">System.out.println(&quot;U=================&quot;);</span><br></pre></td></tr></table></figure><p>控制台输出结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">U============================================================</span><br><span class="line">org.apache.spark.mllib.linalg.distributed.RowMatrix@25c2a9e3</span><br><span class="line">U============================================================</span><br></pre></td></tr></table></figure><h1 id="三、优缺点"><a href="#三、优缺点" class="headerlink" title="三、优缺点"></a><strong>三、优缺点</strong></h1><p><strong>降维的好处</strong>：减小数据维度和需要的存储空间，节约模型训练计算时间，去掉冗余变量，提高算法的准确度，有利于数据可视化。简化数据，去除噪声点，提高算法的结果。</p><p><strong>缺点</strong>：数据的转换可能难以理解；</p><p><strong>适用数据类型</strong>：数值型。</p><h1 id="四、-应用"><a href="#四、-应用" class="headerlink" title="四、 应用"></a><strong>四、 应用</strong></h1><p>通过SVD对数据的处理，我们可以使用小得多的数据集来表示原始数据集，这样做实际上是去除了噪声和冗余信息，以此达到了优化数据、提高结果的目的。有以下应用：</p><p><strong>隐形语义索引</strong>：最早的SVD应用之一就是信息检索，我们称利用SVD的方法为隐性语义检索（LSI）或隐形语义分析（LSA）</p><p><strong>推荐系统</strong>：SVD的另一个应用就是推荐系统，较为先进的推荐系统先利用SVD从数据中构建一个主题空间，然后再在该空间下计算相似度，以此提高推荐的效果。</p><p><strong>参考资料</strong>：</p><ul><li><a href="http://spark.apache.org/docs/latest/mllib-dimensionality-reduction.html" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/mllib-dimensionality-reduction.html</a></li></ul></div><footer><div class="categories"><a href="/categories/machinelearning/">机器学习</a></div><div class="tags"><a href="/tags/content/">content</a>, <a href="/tags/machine-learning/">machine learning</a></div><div class="addthis addthis_toolbox addthis_default_style"><a class="addthis_button_facebook_like" fb:like:layout="button_count"></a> <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a> <a class="addthis_counter addthis_pill_style"></a></div><script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script><div class="clearfix"></div></footer></div></article><section id="comment"><h1 class="title">留言</h1><div id="fb-root"></div><script>!function(e,t,n){var a,c=e.getElementsByTagName(t)[0];e.getElementById(n)||((a=e.createElement(t)).id=n,a.src="//connect.facebook.net/en_US/all.js#xfbml=1&appId=123456789012345",c.parentNode.insertBefore(a,c))}(document,"script","facebook-jssdk")</script><div class="fb-comments" data-href="http://wangpengcufe.github.io/machinelearning/ml-ml7/index.html" data-num-posts="5" data-width="840" data-colorscheme="light"></div></section></div></div><aside id="sidebar" class="alignright"><script language="javascript">function search(e){return e.method="get",e.action="http://www.baidu.com/baidu",document.search_form.word.value=document.search_form.word.value,!0}</script><div class="search"><form name="search_form" target="_blank" onsubmit="search(this)"><input type="search" name="word" results="0" placeholder="百度站内搜索" onblur='this.value=""'></form></div><div class="widget tag"><h3 class="title">分类</h3><ul class="entry"><li><a href="/categories/read/">read</a><small>54</small></li><li><a href="/categories/tools/">工具</a><small>2</small></li><li><a href="/categories/machinelearning/">机器学习</a><small>13</small></li><li><a href="/categories/navigate/">菜单导航</a><small>1</small></li><li><a href="/categories/datadownload/">资料下载</a><small>1</small></li></ul></div><div class="widget tag"><h3 class="title">标签</h3><ul class="entry"><li><a href="/tags/content/">content</a><small>68</small></li><li><a href="/tags/library/">library</a><small>1</small></li><li><a href="/tags/machine-learning/">machine learning</a><small>13</small></li><li><a href="/tags/navigate/">navigate</a><small>1</small></li><li><a href="/tags/tools/">tools</a><small>2</small></li></ul></div><div class="widget tag"><h3 class="title">友情链接</h3><ul class="entry"><li><a href="http://blog.didispace.com" title="程序员DD">程序员DD</a></li><li><a href="https://mangoroom.cn" title="芒果的个人博客">芒果的个人博客</a></li><li><a href="http://www.baimin.com" target="_blank">百鸣网站百科</a></li><li><a href="http://blog.sina.com.cn/u/2435344920" target="_blank">默默读书</a></li></ul></div></aside><div class="clearfix"></div></div><footer id="footer" class="inner"><div class="alignleft">&copy; 2019 王小鹏 京ICP备19037345号-1</div><div class="clearfix"></div><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></footer><script src="//ajax.useso.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script><script src="/js/jquery.imagesloaded.min.js"></script><script src="/js/gallery.js"></script><link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css"><script src="/fancybox/jquery.fancybox.pack.js"></script><script type="text/javascript">jQuery(".fancybox").fancybox()</script></body></html>