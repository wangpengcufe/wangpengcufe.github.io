<!DOCTYPE HTML><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta name="baidu-site-verification" content="kZmc8XTvrB"><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?458cfc1440d057b6b8799400c6b2e2bf";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><meta charset="utf-8"><title>python 机器学习（二）分类算法-k近邻算法 | 机器学习 and 数据科学</title><meta name="author" content="王小鹏  京ICP备19037345号-1"><meta name="keywords" content="机器学习,分类算法,k近邻算法 PDF电子书下载,电子书，PDF下载"><meta name="description" content="PDF电子书下载,电子书，PDF下载"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta property="og:title" content="python 机器学习（二）分类算法-k近邻算法"><meta property="og:site_name" content="机器学习 and 数据科学"><meta property="og:image" content><link href="/favicon.png" rel="icon"><link rel="alternate" href="/atom.xml" title="机器学习 and 数据科学" type="application/atom+xml"><link rel="stylesheet" href="/css/style.css" media="screen" type="text/css"><!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]--></head><body><header id="header" class="inner"><div class="alignleft"><h1><a href="/">机器学习 and 数据科学</a></h1><h2><a href="/">明天幸福今天修</a></h2></div><nav id="main-nav" class="alignright"><ul><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/about">关于</a></li></ul><div class="clearfix"></div></nav><div class="clearfix"></div></header><div id="content" class="inner"><div id="main-col" class="alignleft"><div id="wrapper"><article id="post-pythonml-pythonml2" class="h-entry post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting"><div class="post-content"><header><div class="icon"></div><time class="dt-published" datetime="2020-01-21T09:02:06.000Z"><a href="/machinelearning/pythonml-pythonml2/">2020-01-21</a><span id="busuanzi_container_page_pv"> &nbsp;&nbsp;&nbsp;&nbsp;阅读 <span id="busuanzi_value_page_pv"></span></span></time><h1 class="p-name title" itemprop="headline name">python 机器学习（二）分类算法-k近邻算法</h1></header><div class="e-content entry" itemprop="articleBody"><p><img src="http://wangpengcufe.com/pythonml2.1.png" alt="分类算法-K近邻算法"></p><h1 id="一、什么是K近邻算法？"><a href="#一、什么是K近邻算法？" class="headerlink" title="一、什么是K近邻算法？"></a><strong>一、什么是K近邻算法</strong>？</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义:"></a><strong>定义:</strong></h2><p>如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。</p><h2 id="来源"><a href="#来源" class="headerlink" title="来源:"></a><strong>来源:</strong></h2><p>KNN算法最早是由Cover和Hart提出的一种分类算法.</p><h2 id="计算距离公式"><a href="#计算距离公式" class="headerlink" title="计算距离公式:"></a><strong>计算距离公式:</strong></h2><p>两个样本的距离可以通过如下公式计算，又叫欧式距离。<br>比如说，a(a1,a2,a3),b(b1,b2,b3)<br><img src="http://wangpengcufe.com/pythonml2.2.png" alt="欧式距离"></p><h1 id="二、K近邻算法的实现"><a href="#二、K近邻算法的实现" class="headerlink" title="二、K近邻算法的实现"></a><strong>二、K近邻算法的实现</strong></h1><h2 id="sk-learn近邻算法API"><a href="#sk-learn近邻算法API" class="headerlink" title="sk-learn近邻算法API"></a><strong>sk-learn近邻算法API</strong></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sklearn.neighbors.KNeighborsClassifier(n_neighbors=5,algorithm=&apos;auto&apos;)</span><br><span class="line">n_neighbors：int,可选（默认= 5），k_neighbors查询默认使用的邻居数 </span><br><span class="line">algorithm：&#123;‘auto’，‘ball_tree’，‘kd_tree’，‘brute’&#125;，可选用于计算最近邻居的算法：‘ball_tree’将会使用 BallTree，‘kd_tree’将使用 KDTree。‘auto’将尝试根据传递给fit方法的值来决定最合适的算法。 (不同实现方式影响效率)</span><br></pre></td></tr></table></figure><h2 id="近邻算法实例"><a href="#近邻算法实例" class="headerlink" title="近邻算法实例"></a><strong>近邻算法实例</strong></h2><p>案例背景：（kaggle地址：<a href="https://www.kaggle.com/c/facebook-v-predicting-check-ins/overview）" target="_blank" rel="noopener">https://www.kaggle.com/c/facebook-v-predicting-check-ins/overview）</a><br><img src="http://wangpengcufe.com/pythonml2.3.png" alt="预测入住"></p><p>数据下载地址：<a href="https://storage.googleapis.com/kagglesdsdata/competitions/5186/37497/train.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1579794270&Signature=dUw4i0K1VJJ7UfiSVvXmPiMRhx9v2aPh1eJagNdOQIpdM%2F7CjfhO7K3VLg5Oxd8%2BD%2B9XJqggolwF63CsmOLEPEyBb5BL7g6YRriltjCf1gwJUFx3u2ax6dfjfsyr%2FY4x5hKrrRSpqFPwd4SN9TzUrwcMf7erFxreIpWrO8peG7T%2Fw1EyxNkbH0NGBgYEZ20n0TgYstGGS30fjdoB8mus%2B747tNaWsudQXv5MCr9XRdC8IT95klZ8R5pqNb5tMoIKYaZRwmM5N2clianWQ1knAALW%2Fmpa536gQM%2BbLDzGCUX48rLbwHiZYGE45EEAEGtNdnwM0CUOBojJ2c7UfoeK8g%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain.csv.zip" target="_blank" rel="noopener">train.csv</a></p><p>数据格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">            row_id       x       y  accuracy    time    place_id</span><br><span class="line">0                0  0.7941  9.0809        54  470702  8523065625</span><br><span class="line">1                1  5.9567  4.7968        13  186555  1757726713</span><br><span class="line">2                2  8.3078  7.0407        74  322648  1137537235</span><br><span class="line">3                3  7.3665  2.5165        65  704587  6567393236</span><br><span class="line">4                4  4.0961  1.1307        31  472130  7440663949</span><br><span class="line">...            ...     ...     ...       ...     ...         ...</span><br><span class="line">29118016  29118016  6.5133  1.1435        67  399740  8671361106</span><br><span class="line">29118017  29118017  5.9186  4.4134        67  125480  9077887898</span><br><span class="line">29118018  29118018  2.9993  6.3680        67  737758  2838334300</span><br><span class="line">29118019  29118019  4.0637  8.0061        70  764975  1007355847</span><br><span class="line">29118020  29118020  7.4523  2.0871        17  102842  7028698129</span><br><span class="line"></span><br><span class="line">[29118021 rows x 6 columns]</span><br></pre></td></tr></table></figure><p>实现思路：<br>1、数据集的处理(缩小数据集范围，处理日期数据，增加分割的日期数据，删除没用的日期数据，将签到位置少于n个用户的删除)<br>2、分割数据集<br>3、对数据集进行标准化<br>4、estimator流程进行分类预测</p><p>具体代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"># 读取数据</span><br><span class="line">data = pd.read_csv(&quot;./data/FBlocation/train.csv&quot;)</span><br><span class="line"># 处理数据</span><br><span class="line"># 1、缩小数据,查询数据集范围</span><br><span class="line">data = data.query(&quot;x &gt; 1.0 &amp;  x &lt; 1.25 &amp; y &gt; 2.5 &amp; y &lt; 2.75&quot;)</span><br><span class="line"># 处理时间的数据</span><br><span class="line">time_value = pd.to_datetime(data[&apos;time&apos;], unit=&apos;s&apos;)</span><br><span class="line"> # 把日期格式转换成 字典格式</span><br><span class="line">time_value = pd.DatetimeIndex(time_value)</span><br><span class="line"># 构造一些特征</span><br><span class="line">data[&apos;day&apos;] = time_value.day</span><br><span class="line">data[&apos;hour&apos;] = time_value.hour</span><br><span class="line">data[&apos;weekday&apos;] = time_value.weekday</span><br><span class="line"># 把时间戳特征删除</span><br><span class="line">data = data.drop([&apos;time&apos;], axis=1)</span><br><span class="line"># 把签到数量少于n个目标位置删除</span><br><span class="line">place_count = data.groupby(&apos;place_id&apos;).count()</span><br><span class="line">tf = place_count[place_count.row_id &gt; 3].reset_index()</span><br><span class="line">data = data[data[&apos;place_id&apos;].isin(tf.place_id)]</span><br><span class="line"></span><br><span class="line"># 取出数据当中的特征值和目标值</span><br><span class="line">y = data[&apos;place_id&apos;]</span><br><span class="line">x = data.drop([&apos;place_id&apos;], axis=1)</span><br><span class="line"># 进行数据的分割训练集合测试集</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)</span><br><span class="line"># 特征工程（标准化）</span><br><span class="line">std = StandardScaler()</span><br><span class="line"># 对测试集和训练集的特征值进行标准化</span><br><span class="line">x_train = std.fit_transform(x_train)</span><br><span class="line">x_test = std.transform(x_test)</span><br><span class="line"># 进行算法流程 # 超参数</span><br><span class="line">knn = KNeighborsClassifier()</span><br><span class="line">knn.fit(x_train, y_train)</span><br><span class="line">y_predict = knn.predict(x_test)</span><br><span class="line">print(&quot;预测的目标签到位置为：&quot;, y_predict)</span><br><span class="line">print(&quot;预测的准确率:&quot;, knn.score(x_test, y_test))</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">预测的目标签到位置为： [8258328058 2355236719 6683426742 ... 5606572086 4932578245 9237487147]</span><br><span class="line">预测的准确率: 0.3959810874704492</span><br></pre></td></tr></table></figure><h2 id="思考问题"><a href="#思考问题" class="headerlink" title="思考问题"></a><strong>思考问题</strong></h2><p>1、k值取多大？有什么影响？<br>2、性能问题？</p><h1 id="三、K近邻算法总结"><a href="#三、K近邻算法总结" class="headerlink" title="三、K近邻算法总结"></a><strong>三、K近邻算法总结</strong></h1><h2 id="K近邻算法优缺点"><a href="#K近邻算法优缺点" class="headerlink" title="K近邻算法优缺点"></a><strong>K近邻算法优缺点</strong></h2><p><strong>优点</strong>：<br>简单，易于理解，易于实现，无需估计参数，无需训练</p><p><strong>缺点</strong></p><ul><li>懒惰算法，对测试样本分类时的计算量大，内存开销大</li><li>必须指定K值，K值选择不当则分类精度不能保证</li></ul><h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a><strong>使用场景</strong></h2><p>小数据场景，几千～几万样本，具体场景具体业务去测试</p><h1 id="四、分类模型的评估"><a href="#四、分类模型的评估" class="headerlink" title="四、分类模型的评估"></a><strong>四、分类模型的评估</strong></h1><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a><strong>评估方法</strong></h2><p>estimator.score()<br>一般最常见使用的是准确率，即预测结果正确的百分比</p><p><strong>混淆矩阵</strong><br>在分类任务下，预测结果(Predicted Condition)与正确标记(True Condition)之间存在四种不同的组合，构成混淆矩阵(适用于多分类)<br><img src="http://wangpengcufe.com/pythonml2.4.png" alt="混淆矩阵"><br><strong>精确率（Precision）</strong>：预测结果为正例样本中真实为正例的比例（查得准）<br><img src="http://wangpengcufe.com/pythonml2.5.png" alt="精确率（Precision）"><br><strong>召回率(Recall)</strong>：真实为正例的样本中预测结果为正例的比例（查的全，对正样本的区分能力）<br><img src="http://wangpengcufe.com/pythonml2.6.png" alt="召回率(Recall)"><br>其他分类标准，<strong>F1-score</strong>，反映了模型的稳健型<br><img src="http://wangpengcufe.com/pythonml2.7.png" alt="F1-score"></p><h2 id="分类模型评估API"><a href="#分类模型评估API" class="headerlink" title="分类模型评估API"></a><strong>分类模型评估API</strong></h2><p>评估API ：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.classification_report</span><br></pre></td></tr></table></figure><p>用法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.classification_report(y_true, y_pred, target_names=None)</span><br><span class="line"></span><br><span class="line">y_true：真实目标值</span><br><span class="line"></span><br><span class="line">y_pred：估计器预测目标值</span><br><span class="line"></span><br><span class="line">target_names：目标类别名称</span><br><span class="line"></span><br><span class="line">return：每个类别精确率与召回率</span><br></pre></td></tr></table></figure></div><footer><div class="categories"><a href="/categories/machinelearning/">机器学习</a></div><div class="tags"><a href="/tags/content/">content</a>, <a href="/tags/machine-learning/">machine learning</a></div><div class="addthis addthis_toolbox addthis_default_style"><a class="addthis_button_facebook_like" fb:like:layout="button_count"></a> <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a> <a class="addthis_counter addthis_pill_style"></a></div><script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script><div class="clearfix"></div></footer></div></article><section id="comment"><h1 class="title">留言</h1><div id="fb-root"></div><script>!function(e,t,n){var a,c=e.getElementsByTagName(t)[0];e.getElementById(n)||((a=e.createElement(t)).id=n,a.src="//connect.facebook.net/en_US/all.js#xfbml=1&appId=123456789012345",c.parentNode.insertBefore(a,c))}(document,"script","facebook-jssdk")</script><div class="fb-comments" data-href="http://www.wangpengcufe.com/machinelearning/pythonml-pythonml2/index.html" data-num-posts="5" data-width="840" data-colorscheme="light"></div></section></div></div><aside id="sidebar" class="alignright"><script language="javascript">function search(e){return e.method="get",e.action="http://www.baidu.com/baidu",document.search_form.word.value=document.search_form.word.value,!0}</script><div class="search"><form name="search_form" target="_blank" onsubmit="search(this)"><input type="search" name="word" results="0" placeholder="百度站内搜索" onblur='this.value=""'></form></div><div class="widget tag"><h3 class="title">分类</h3><ul class="entry"><li><a href="/categories/read/">read</a><small>65</small></li><li><a href="/categories/tools/">工具</a><small>2</small></li><li><a href="/categories/machinelearning/">机器学习</a><small>22</small></li><li><a href="/categories/navigate/">菜单导航</a><small>1</small></li><li><a href="/categories/datadownload/">资料下载</a><small>1</small></li></ul></div><div class="widget tag"><h3 class="title">标签</h3><ul class="entry"><li><a href="/tags/content/">content</a><small>88</small></li><li><a href="/tags/library/">library</a><small>1</small></li><li><a href="/tags/machine-learning/">machine learning</a><small>22</small></li><li><a href="/tags/navigate/">navigate</a><small>1</small></li><li><a href="/tags/tools/">tools</a><small>2</small></li></ul></div><div class="widget tag"><h3 class="title">友情链接</h3><ul class="entry"><li><a href="http://blog.didispace.com" title="程序员DD">程序员DD</a></li><li><a href="https://mangoroom.cn" title="芒果的个人博客">芒果的个人博客</a></li><li><a href="http://www.baimin.com" target="_blank">百鸣网站百科</a></li><li><a href="http://blog.sina.com.cn/u/2435344920" target="_blank">默默读书</a></li><li><a href="https://www.jianshu.com/u/510007ddad06" target="_blank">王小鹏的随笔（简书）</a></li><li><a href="https://me.csdn.net/weixin_42438712" target="_blank">机器学习（csdn博客）</a></li><li><a href="https://zhuanlan.zhihu.com/c_1182309165824901120" target="_blank">机器学习（知乎）</a></li><li><a href="http://meixiaohan.com/" target="_blank">小寒大人的blog</a></li><li><a href="https://baippt.com/" target="_blank">ppt模板免费下载</a></li><li><a href="http://www.youneedcn.com/" target="_blank">你要的资源</a></li></ul></div></aside><div class="clearfix"></div></div><footer id="footer" class="inner"><div class="alignleft">&copy; 2020 王小鹏 京ICP备19037345号-1</div><div class="clearfix"></div><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></footer><script src="//ajax.useso.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script><script src="/js/jquery.imagesloaded.min.js"></script><script src="/js/gallery.js"></script><link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css"><script src="/fancybox/jquery.fancybox.pack.js"></script><script type="text/javascript">jQuery(".fancybox").fancybox()</script></body></html>